{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[{"file_id":"1HZ55tIreDr1ZHZxfMuKux1ujNdBjCgvr","timestamp":1574608324036}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Tife19NxBeR8","colab_type":"code","outputId":"308c353e-3d39-4102-af16-a9c53856ac0b","executionInfo":{"status":"ok","timestamp":1578759040546,"user_tz":-60,"elapsed":16957,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import tensorflow_datasets.public_api as tfds\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv2D, Input, InputLayer, MaxPool2D, UpSampling2D, BatchNormalization, Dropout, Conv2DTranspose, ReLU, Activation\n","from tensorflow.keras.backend import concatenate\n","import scipy.stats as ss\n","from scipy.stats import entropy, zscore, moment\n","import os\n","import time\n","import imageio\n","import random\n","import collections\n","import copy\n","import glob\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","from itertools import chain\n","from sklearn.preprocessing import MinMaxScaler\n","from skimage.transform import resize\n","from skimage import draw\n","from skimage.transform import rotate\n","from IPython.display import Image\n","!pip install tf-explain\n","from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","Collecting tf-explain\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ce/993daad6523c5dfe250e55746eb137677b66ac085670180d9fa17783170f/tf_explain-0.2.0-py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.0MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from tf-explain) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.3 in /tensorflow-2.1.0/python3.6 (from opencv-python>=4.1.0.25->tf-explain) (1.18.1)\n","Installing collected packages: tf-explain\n","Successfully installed tf-explain-0.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Q_WgtDA001I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"80715078-5212-4a2d-b487-306c3e12bbc0","executionInfo":{"status":"ok","timestamp":1578759058188,"user_tz":-60,"elapsed":34552,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YovsqgRXkLC8","colab_type":"code","colab":{}},"source":["im_dims = (32, 64, 1) # Image dimensions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IAUQjnGBg59","colab_type":"code","cellView":"both","colab":{}},"source":["class Shape(object):\n","    '''\n","    A class to generate shapes\n","    '''\n","    def __init__(self, size, size_range, pos, xgap, offset=0):\n","        '''\n","        size: size of object (circle: radius, other shapes: length)\n","        size_range: [mininmum size, maximum size] for given shape\n","        pos: initial position\n","        xgap: x-axis gap between shapes\n","        offset: y-axis offset/shift value of second shape (compared to first shape's y-axis position)\n","        '''\n","        self.size = size\n","        self.min_size, self.max_size = size_range[0], size_range[1]\n","        self.xgap = xgap\n","        self.pos = [pos[0] + xgap, pos[1] + offset] \n","    \n","    def generate(self, drawFun, **kwargs):\n","        '''\n","        Drawing function\n","        Each shape has a drawing function provided by scikit-image\n","\n","        returns: rows and columns of np array\n","        '''\n","        rr, cc = drawFun(**kwargs)\n","        return rr, cc   \n","        \n","class Circle(Shape):\n","    '''\n","    A class to generate circles\n","    '''\n","    def __init__(self, size=4, size_range=(2, 4), pos=[0,0], offset=0):\n","        self.xgap = size/2\n","        super().__init__(size, size_range, pos, self.xgap, offset)\n","    \n","    def generate(self):\n","        return super().generate(draw.circle, r=self.pos[0], c = self.pos[1], radius=self.size)\n","\n","class Triangle(Shape):\n","    '''\n","    A class to generate triangles (as a polygon)\n","    '''\n","    def __init__(self, size=5, size_range=(3, 6), pos=[0,0], offset=0):\n","        self.xgap = 0\n","        super().__init__(size, size_range, pos, self.xgap, offset)\n","    \n","    def generate(self):\n","        poly = self.polygonArray()\n","        return super().generate(draw.polygon, r=poly[:,0], c=poly[:, 1])\n","    \n","    def polygonArray(self):\n","        '''\n","        Get all summits of triangle polygon\n","        '''\n","        return np.array((\n","                        (self.pos[0], self.pos[1]),\n","                        (self.pos[0] + np.sqrt(3)*self.size/2, self.pos[1]-self.size/2),\n","                        (self.pos[0] + np.sqrt(3)*self.size/2, self.pos[1]+self.size/2),\n","                        (self.pos[0], self.pos[1]), \n","                        ))\n","\n","class Diamond(Shape):\n","    '''\n","    A class to generate diamonds (as a polygon)\n","    '''\n","    def __init__(self, size=4, size_range=(3, 5), pos=[0,0], offset=0):\n","        self.xgap = size/4\n","        super().__init__(size, size_range, pos, self.xgap, offset)\n","    \n","    def generate(self):\n","        poly = self.polygonArray()\n","        return super().generate(draw.polygon, r=poly[:,0], c=poly[:, 1])\n","\n","    def polygonArray(self):\n","        '''\n","        Get all summits of diamond polygon\n","        '''\n","        return np.array((\n","                        (self.pos[0], self.pos[1]),\n","                        (self.pos[0] + np.sqrt(3)*self.size/2, self.pos[1]-self.size/2),\n","                        (self.pos[0] + np.sqrt(3)*self.size, self.pos[1]),\n","                        (self.pos[0] + np.sqrt(3)*self.size/2, self.pos[1]+self.size/2),\n","                        (self.pos[0], self.pos[1]),\n","                        ))\n","\n","class Line(Shape):\n","    '''\n","    A class to generate lines\n","    '''\n","    def __init__(self, size=4, size_range=(3,6), pos=[0,0], offset=0):\n","        self.xgap = 0\n","        super().__init__(size, size_range, pos, self.xgap, offset)\n","    \n","    def generate(self):\n","        return super().generate(draw.line, r0=int(self.pos[0]), c0=int(self.pos[1]), \n","                                r1=int(self.pos[0]+self.size), c1=int(self.pos[1]))    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNA3z24KBkbi","colab_type":"code","cellView":"both","colab":{}},"source":["class ShapePair():\n","  '''\n","  A class for pairs of shape\n","  s1: 1st shape\n","  s2: 2nd shape\n","  size: size of both shapes\n","  '''\n","\n","  def __init__(self, shape1, shape2):\n","    self.s1 = shape1\n","    self.s2 = shape2\n","    self.size = shape1.size\n","  \n","  def resize(self, _size):\n","    '''\n","    Size setter for both shapes\n","    '''\n","    self.s1.size = _size\n","    self.s2.size = _size\n","    self.size = _size\n","  \n","  def setPos(self, xpos, ypos, offset=0):\n","    '''\n","    Initial position setter for both shapes\n","    '''\n","    self.s1.pos = [xpos - self.size - self.s1.xgap, ypos]\n","    self.s2.pos = [xpos + self.size + self.s1.xgap, ypos + offset]\n","  \n","  def fillArray(self, arr, xpos, ypos, offset):\n","    '''\n","    Fill numpy array with given positions of both shapes for drawing\n","    '''\n","\n","    self.setPos(xpos, ypos, offset)\n","\n","    rr, cc = self.s1.generate()\n","    rr2, cc2 = self.s2.generate()\n","    arr[rr, cc, :] = 1. # Fill array with coordinates from 1st shape\n","    arr[rr2, cc2, :] = 1. # Fill array with coordinates from 2nd shape\n","    return arr\n","  \n","  def generateDataset(self, im_dims, nShapes):\n","    '''\n","    Dataset generator\n","    '''\n","\n","    np.random.seed(42)\n","    \n","    data_list = []\n","    \n","    sizes = np.random.randint(self.s1.min_size, self.s1.max_size, nShapes) # Random sizes\n","\n","    xc = im_dims[0]//2 # Center x-coordinate\n","    yc = im_dims[1]//2 # Center y-coordinate\n","    \n","    for size in sizes:\n","      self.resize(size) # Resize shapes with random size\n","\n","      # Generate random initial position (around center of image)\n","      xpos = np.random.uniform(xc-0.25*size, xc+0.25*size)\n","      ypos = np.random.uniform(yc-0.5*size, yc+0.5*size)\n","\n","      # Generate random offset\n","      offset = (1 if np.random.random() > 0.5 else -1)*size\n","\n","      # Generate surrounding offsets (for fuzzy motion batch)\n","      # \"Fuzzy\" motion batch is equivalent to generating the motion for 3 shape pairs with different offsets\n","      # Then, for each frame one shape pair is chosen among the three in a periodic fashion\n","      inf_offset = offset - 2\n","      sup_offset = offset + 2\n","      list_off = [offset, inf_offset, sup_offset]\n","      arr, inf_arr, sup_arr = np.zeros(im_dims), np.zeros(im_dims), np.zeros(im_dims)\n","      list_arr = [arr, inf_arr, sup_arr]\n","\n","      # Fill three arrays with initial positions \n","      for i in range(len(list_arr)):\n","         list_arr[i] = self.fillArray(list_arr[i], xpos, ypos, list_off[i])\n","\n","      # Append to general dataset\n","      data_list.append(list_arr)\n","    return data_list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rMCM3UktdxJf","colab_type":"text"},"source":["Reconstructor dataset generation"]},{"cell_type":"code","metadata":{"id":"HWamJok4WCFd","colab_type":"code","cellView":"both","colab":{}},"source":["def generateReconsDataset(im_dims, n_circles=2500, n_diamonds=2500, n_triangles=2500, n_lines=2500):\n","  '''\n","  Reconstruction dataset generator\n","  im_dims: image dimensions\n","  n_circles: number of circles\n","  n_diamonds: number of diamonds\n","  n_triangles: number of triangles\n","  n_lines: number of lines\n","\n","  Returns: the reconstruction dataset (as a list)\n","  '''\n","  # Generate a shape pair for each shape\n","  cc1 = ShapePair(Circle(), Circle())\n","  dd1 = ShapePair(Diamond(), Diamond())\n","  tt1 = ShapePair(Triangle(), Triangle())\n","  ll1 = ShapePair(Line(), Line())\n","  \n","  # Generate dataset for each shape\n","  c_list = cc1.generateDataset(im_dims, n_circles)\n","  d_list = dd1.generateDataset(im_dims, n_diamonds)\n","  t_list = tt1.generateDataset(im_dims, n_triangles)\n","  l_list = ll1.generateDataset(im_dims, n_lines)\n","  \n","  # Merge all datasets\n","  data_list = c_list + d_list + t_list + l_list\n","  \n","  print('Circles: %d, Diamonds: %d, Triangles: %d, Lines: %d, Total: %d'\n","        % (len(c_list), len(d_list), len(t_list), len(l_list), len(data_list)))\n","  return data_list\n","\n","def split_data(data_list, labels=None, seed=8):\n","  '''\n","  Split dataset into training and test sets \n","  '''\n","  dataset = np.array(data_list)\n","\n","  n = len(dataset)\n","  n_test = int(n*0.15) # nb of test elements: 15%\n","  n_train = n-n_test   # nb of train elements: 85%\n","\n","  train_images, test_images = tf.split(tf.random.shuffle(dataset, seed), [n_train, n_test], 0)\n","    \n","  print('Whole dataset dimensions: ', dataset.shape)\n","  print('Training dataset dimensions: ', train_images.shape)\n","  print('Test dataset dimensions: ', test_images.shape)\n","  \n","  # Labels are only present for decoder datasets (0 = left offset, 1 = right offset)\n","  if (labels != None):\n","    print('Labels found.')\n","    train_labels, test_labels = tf.split(tf.random.shuffle(decoder_labels, seed), [n_train, n_test], 0)\n","    return train_images, test_images, train_labels, test_labels\n","  else:\n","    return train_images, test_images"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYzZ2bAYeO4G","colab_type":"text"},"source":["Decoder dataset generation"]},{"cell_type":"code","metadata":{"id":"HueWhG5HWRi0","colab_type":"code","cellView":"code","colab":{}},"source":["def generateDecoderDataset(im_dims, N=10000, length=4):\n","  '''\n","  Decoder dataset generator\n","  im_dims: image dimensions\n","  N: number of examples\n","  length: length of a line\n","\n","  Returns: the decoder data (as a list), its labels and a list of offset values for each example\n","  '''\n","\n","  # Set maximum gap between shapes (along x-axis) and maximum offset value\n","  max_gap = length/2\n","  max_offset = length/2\n","\n","  # Generate random positions for decoder vernier (or vernier pairs)\n","  x_pos = np.random.uniform(length, im_dims[0]-2*length-max_gap, (N)) # --> For im_dims = 32 on x-axis: [4, 32-2*4-4=20]\n","  y_pos = np.random.uniform(max_offset, im_dims[1]-max_offset, (N)) # --> For im_dims = 64 on y-axis: [2, 64-2=32]\n","  \n","  x_gaps = np.random.uniform(0, max_gap, (N)) # Gaps between lines\n","\n","  decoder_list = []\n","  decoder_labels = []\n","\n","  # Decoder dataset only consists of lines\n","  ll1 = ShapePair(Line(size=length), Line(size=length))\n","\n","  offsets = []\n","\n","  for i in range(N):\n","    arr = np.zeros(im_dims)\n","\n","    # Generate random offset (left or right)\n","    off = max_offset*(1 if np.random.random() > 0.5 else -1)\n","\n","    # Collect offsets\n","    offsets.append(off)\n","\n","    # Initial position\n","    x, y = x_pos[i] + x_gaps[i], y_pos[i]\n","\n","    decoder_labels.append(off > 0) # 1 = right, 0 = left\n","\n","    # Fill array with given position and offset\n","    ll1.fillArray(arr, int(x), int(y), int(off))\n","\n","    decoder_list.append(arr)\n","  \n","  return decoder_list, decoder_labels, offsets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nr7FSa8TfA9m","colab_type":"text"},"source":["Test set generation (SQM generation)"]},{"cell_type":"code","metadata":{"id":"CSRJsstrBnXF","colab_type":"code","cellView":"both","colab":{}},"source":["def offsetGenerator():\n","  '''\n","  Random offset generator\n","  Offset is generated between -3 and -1 (for left offsets) and between 1 and 3 (for right offsets)\n","  '''\n","  return np.random.randint(1,4)*(1 if np.random.random() > 0.5 else -1) # [-3, -1] u [1, 3]\n","\n","def inputSpeed():\n","  # Ask for input speed between frames (Not used)\n","  return int(input('Enter horizontal speed: '))\n","\n","def inputTestOffsets(case='vpv'):\n","  '''\n","  Ask user to enter his offsets\n","  case: vpv, vav or v (i.e., the SQM paradigms)\n","  '''\n","\n","  n_frames = 13\n","  off_val = offsetGenerator()\n","  all_off_vals = [0] * n_frames\n","\n","  off_pos = 6 # Position at which a flanking vernier will be offset\n","  all_off_vals[0] = off_val # Set offset at first frame\n","\n","  # If VPV or VAV, need to set offset values at other frames\n","  if case == 'vpv':\n","    # VPV: the same offset value is applied at both the central and the chosen flanking vernier\n","    all_off_vals[off_pos] = off_val \n","  elif case == 'vav':\n","    # VPV: the opposite offset value is applied between the central vernier and the chosen flanking vernier\n","    all_off_vals[off_pos] = -off_val\n","\n","  # Gather offset paramaters as dictionary\n","  off_dict = dict(zip(range(n_frames), all_off_vals)) \n","\n","  # Order dictionary (not necessarily necessary)\n","  off_dict = collections.OrderedDict(sorted(off_dict.items()))\n","  return off_dict, off_pos\n","\n","def inputUserOffsets():\n","  '''\n","  Ask user to enter his offset parameters\n","\n","  Returns: list of offsets (as a dictionary: key = frame index, value = offset value)\n","  '''\n","  # Input to user\n","  raw_off = input('Enter list of offsets as \"position1, value1, position2, value2...\": ')\n","  \n","  # Convert raw input to list of ints\n","  off = list(map(int, raw_off.split(',')))\n","  \n","  # Convert to dictionary: key = offset position, value = offset value\n","  pos, vals = off[::2], off[1::2]\n","  off_dict = dict(zip(pos, vals))\n","  \n","  # Add missing positions with zero-valued offsets for n_frames\n","  for i in range(10):\n","    if not(i in off_dict):\n","      off_dict[i] = 0\n","  \n","  # Convert to ordered dictionary\n","  off_dict = collections.OrderedDict(sorted(off_dict.items()))\n","  \n","  # Print for user\n","  print('Offsets: ')\n","  print(off_dict)\n","  \n","  return off_dict\n","\n","def generateTestSet(im_dims, n_frames=10, length=4, case='vpv', dy = 3):\n","  '''\n","  Generate test set\n","  '''\n","\n","  # Ask user to input frame speed if dy is not given\n","  if dy == None:\n","    dy = inputSpeed() # Speed only along y axis\n","\n","  offsets, off_pos = inputTestOffsets(case)\n","  c_off = offsets[0]\n","  \n","  x_pos = im_dims[0]//2\n","  y_pos = im_dims[1]//2\n","  \n","  # Central vernier\n","  ll1 = ShapePair(Line(size=length), Line(size=length))\n","  arr = np.zeros(im_dims)\n","  arr = ll1.fillArray(arr, x_pos, y_pos, c_off)\n","  init_nnz = np.count_nonzero(arr)\n","  frames = [arr]\n","  labels = [c_off > 0]\n","\n","  # Generate flanking verniers\n","  for i in range(1, n_frames):\n","    # Build frame\n","    arr = np.zeros(im_dims)\n","    arr1, arr2 = arr, arr\n","\n","    off = offsets[i] # Offset value for current frame\n","    \n","    # Create left and right verniers\n","    left, right = copy.deepcopy(ll1), copy.deepcopy(ll1)\n","    \n","    # Update y position\n","    y_pos = y_pos - dy\n","    \n","    # Fill intermediate arrays with left and right verniers\n","    arr1 = left.fillArray(arr1, x_pos, y_pos, off)\n","    arr2 = right.fillArray(arr2, x_pos, im_dims[1]-y_pos, 0)\n","\n","    # Frame = left and right vernier on same image\n","    arr = arr1 + arr2\n","    \n","    # Update ll1 for next iteration\n","    ll1.setPos(x_pos, y_pos, off)\n","    \n","    # Check that we are not going out of the image\n","    if (min(np.count_nonzero(arr1), np.count_nonzero(arr2)) < init_nnz):\n","      break\n","    else:\n","      frames.append(arr)\n","      if (off == c_off):\n","        # If the offset value is the same as the central value, then apply same label\n","        labels.append(labels[0])\n","      else:\n","        # Else, apply contrary of central label\n","        labels.append(not(labels[0]))\n","  \n","  # If we went out of the image before n_frames frames were generated, fill other frames with zeros \n","  while (len(frames) < n_frames):\n","    frames.append(np.zeros(arr.shape))\n","    labels.append(not(labels[0]))\n","\n","  # Add Gaussian noise to every frame\n","  noised_frames = [addNoise(frame) for frame in frames]\n","  \n","  return tf.stack(noised_frames), tf.stack(labels)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBSuo4txnu2p","colab_type":"code","cellView":"both","colab":{}},"source":["def generateTestSet2(im_dims, n_frames=10, length=4, case='vpv', dy = 3):\n","  '''\n","  Simili-test set generator for the decoder dataset\n","  Similar to SQM except either the left pair, the right pair or both can be offset (in VPV/VAV conditions)\n","\n","  Returns:\n","  13 decoding frames (3 blank + 10 SQM-like frames), corresponding labels and position at which (a) flanking vernier(s) is/are offset\n","  '''\n","\n","  # Ask user for input speed if \n","  if dy == None:\n","    dy = inputSpeed() # Speed only along y axis\n","\n","  # off_pos -> frame index where offset will appear \n","  offsets, off_pos = inputTestOffsets(case)\n","  c_off = offsets[off_pos] > 0 # Central offset\n","\n","  labels = [c_off for i in range(n_frames)]\n","  \n","  x_pos = im_dims[0]//2\n","  y_pos = im_dims[1]//2\n","  \n","  # Initial frame: cerntral vernier\n","  ll1 = ShapePair(Line(size=length), Line(size=length))\n","  arr = np.zeros(im_dims)\n","  arr = ll1.fillArray(arr, x_pos, y_pos, c_off)\n","  init_nnz = np.count_nonzero(arr)\n","\n","  # Add three blank frames\n","  before_frames = 3*[addNoise(np.zeros(im_dims))]\n","  frames = before_frames + [arr]\n","\n","  # Vernier offseting mode: the left vernier, right vernier or both can be offset\n","  mode = np.random.randint(3)\n","\n","  for i in range(len(frames), n_frames):\n","    # Build frame\n","    arr = np.zeros(im_dims)\n","    arr1, arr2 = arr, arr\n","\n","    off = offsets[i] # Offset value for current frame\n","    \n","    # Create left and right verniers\n","    left, right = copy.deepcopy(ll1), copy.deepcopy(ll1)\n","    \n","    # Update y position\n","    y_pos = y_pos - dy\n","\n","    # Select which verniers (from the flanking verniers) will be offset\n","    # Either the left vernier, or right vernier or both can be offset\n","\n","    if mode == 0: # Default: only left vernier\n","      arr1 = left.fillArray(arr1, x_pos, y_pos, off)\n","      arr2 = right.fillArray(arr2, x_pos, im_dims[1]-y_pos, 0)\n","    elif mode == 1: # only right vernier\n","      arr1 = left.fillArray(arr1, x_pos, y_pos, 0)\n","      arr2 = right.fillArray(arr2, x_pos, im_dims[1]-y_pos, off)\n","    elif mode == 2: # both verniers\n","      arr1 = left.fillArray(arr1, x_pos, y_pos, off)\n","      arr2 = right.fillArray(arr2, x_pos, im_dims[1]-y_pos, off)\n","\n","    # Frame = left and right vernier on same image\n","    arr = arr1 + arr2\n","    \n","    # Update ll1 for next iteration\n","    ll1.setPos(x_pos, y_pos, off)\n","    \n","    # Check that we are not going out of the image\n","    if (min(np.count_nonzero(arr1), np.count_nonzero(arr2)) < init_nnz):\n","      break\n","    else:\n","      frames.append(arr)\n","  \n","  # If we went out of the image, fill with zeros \n","  while (len(frames) < n_frames):\n","    frames.append(np.zeros(arr.shape))\n","\n","  # Add Gaussian noise to every frame\n","  noised_frames = [addNoise(frame) for frame in frames]\n","  \n","  return tf.stack(noised_frames), tf.stack(labels), off_pos"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFjgJhs6Bts-","colab_type":"code","cellView":"both","colab":{}},"source":["# rollPad, generateFrames, addNoise\n","def rollPad(image, dx, dy, pad=0):\n","    '''\n","    Roll image with horizontal and vertical speed\n","    Zero-pad the extremities depending on speed\n","    -> If shape goes out of frame, this can be detected by counting nnz pixels\n","\n","    image: image array\n","    dx: x-rolling speed\n","    dy: y-rolling speed\n","    pad: value for padding at each iteration (to detect whether shapes go out of frame or not)\n","    '''\n","\n","    # Roll image\n","    image = np.roll(image, dx, axis=0)\n","\n","    # Zero-pad boundaries depending on direction of objects\n","    if dx < 0:\n","      image[dx:, :] = pad\n","    elif dx > 0:\n","      image[0:np.abs(dx), :] = pad\n","\n","    image = np.roll(image, dy, axis=1)\n","    if dy < 0:\n","        image[:, dy:] = pad\n","    elif dy > 0:\n","        image[:, 0:dy] = pad\n","    \n","    return image\n","\n","def generateFrames(frames, image, n_frames, dx, dy, init_nnz, before_blanks, after_blanks):\n","  '''\n","  Generate all reconstruction frames given an image:\n","    - Roll image with horizontal and vertical speed\n","    - Append new image unless the shapes go out of the frames\n","    - In that case, append 0-arrays\n","  \n","  frames: list of frames\n","  image: initial image\n","  n_frames: number of frames\n","  dx: x-speed\n","  dy: y-speed\n","  init_nnz: number of non-zero pixels in the initial image (to check if a shape went out of bounds)\n","  before_blanks: number of empty frames added to the mandatory blank before the 10 \"motion frames\" (default: 2 => 3 blanks before)\n","  before_blanks: number of empty frames after the 10 \"motion frames\" (default: 0)\n","\n","  Returns: list of frames, and the number of frames before a shape went out of bounds\n","  '''\n","  # Create temporary images to \"move\" each pair independently\n","  # Then, the images are added -> the final image contains both pairs\n","  tmp1, tmp2 = image, image\n","\n","  # Frame counter \n","  count = 1\n","\n","  # Generate next 9 frames \n","  for t in range(n_frames-3-1):\n","    tmp1 = rollPad(tmp1, dx, dy)\n","    tmp2 = rollPad(tmp2, -dx, -dy)\n","    \n","    image = tmp1 + tmp2\n","    \n","    # If shapes go out of framework, get out of loop...\n","    # And add zero-arrays until nb of frames is reached\n","    if (min(np.count_nonzero(tmp1), np.count_nonzero(tmp2)) < init_nnz):\n","      break\n","    else:\n","      count += 1\n","      frames.append(image)\n","\n","  while (len(frames) < n_frames-3):\n","    frames.append(np.zeros(image.shape))\n"," \n","  frames = addBlanks(frames, image, before_blanks, after_blanks)\n","  # Add noise to frames\n","  return [addNoise(frame) for frame in frames], count\n","\n","def addBlanks(frames, image, before_blanks, after_blanks):\n","  '''\n","  Add blank/empty frames\n","  frames: current frames\n","  image.shape: image dimension\n","  before_blanks: number of empty frames before the 10 frames, added to a first mandatory extra blank\n","  after_blanks: number of empty frames after the 10 frames\n","\n","  Returns: merged frames (Empty frames before the 10 frames + 10 frames + Empty frames after the 10 frames)\n","  '''\n","  frames.insert(0, np.zeros(image.shape)) # First (mandatory) extra blank\n","  return before_blanks*[np.zeros(image.shape)] + frames + after_blanks*[np.zeros(image.shape)]\n","\n","def generateDecoderFrames(frames, image, n_frames, dx, dy, init_nnz):\n","  '''\n","  Generate all decoder frames given an image:\n","    - Roll image with horizontal and vertical speed\n","    - Append new image unless the shapes go out of bounds\n","    - In that case, append 0-arrays until n_frames frames are generated\n","\n","    frames: list of frames (only contains the initial image at the beginning)\n","    image: initial image\n","    n_frames: number of frames to be generated\n","    dx: x-speed\n","    dy: y-speed\n","    init_nnz: number of non-zero pixels in the initial image (to check if a shape went out of bounds)\n","  '''\n","\n","  old_len_nnz = 10 # We want to generate motion for 10 frames\n","  new_len_nnz = old_len_nnz # This value will be the number of frames until a line goes out of bounds\n","  # If no lines go out of bounds, then default value is 10 (the number of frames to generate)\n","\n","  for t in range(1, old_len_nnz):\n","    # \"Roll\" current image\n","    image = rollPad(image, dx, dy)\n","    \n","    # If shapes go out of framework, get out of loop...\n","    # And add zero-arrays until nb of frames is reached\n","    if (np.count_nonzero(image) < init_nnz):\n","      new_len_nnz = len(frames)-1\n","      break\n","    # Else, append built image to list of frames\n","    else:\n","      frames.append(image)\n","\n","  while (len(frames) < old_len_nnz):\n","    frames.append(np.zeros(image.shape))\n","\n","  # Add three blank images before, and none after (default configuration)\n","  frames = addBlanks(frames, image, 2, 0)\n","\n","  # Check that n_frames frames were generated\n","  assert(len(frames) == n_frames)\n","\n","  # As 3 blank images were added, add 3 to the number of frames until a line went out of bounds\n","  return frames, new_len_nnz+3\n","\n","def addNoise(image, mean=0, sd=0.1):\n","  '''\n","  Add Gaussian noise to image, and clip values\n","\n","  Returns clipped (between 0 and 1) noise image\n","  '''\n","  image = image + np.random.normal(mean, sd, image.shape)\n","  return np.clip(image, a_min=0., a_max=1., out=image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBPX02zoBvwt","colab_type":"code","colab":{}},"source":["n_frames = 13\n","n_units = 100 # nb of neurons (not useful for PredNet)'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlxb8i27WfFm","colab_type":"code","colab":{}},"source":["def make_fuzzy_motion_batch(batch_samples):\n","  '''\n","  \"Fuzzy\" motion batch used for reconstruction\n","  I.e., the offset values is seen as oscillating\n","   - Perform three reconstruction motion batches with three different offsets\n","   - Append a frame from one of the three batches (periodically) for each frame\n","  \n","  Returns: the \"fuzzy\" motion batch, with noise and three empty frames before the motion frames\n","  '''\n","\n","  # All three motion batches\n","  motion_batches = []\n","\n","  # List of number of frames before a shape went out of bounds during motion\n","  counts = []\n","\n","  r_vel = np.random.randint(0,2)*2-1\n","  c_vel = (1 if np.random.random() > 0.5 else -1)*np.random.randint(1,4)\n","\n","  before_blanks = 2\n","  after_blanks = 0\n","  \n","  for i in range(batch_samples.shape[1]):\n","    motion_batch, count = make_motion_batch(batch_samples[:,i,:,:,:], r_vel, c_vel, before_blanks, after_blanks)\n","    motion_batches.append(motion_batch)\n","    counts.append(count)\n","  \n","  final_motion_batch = []\n","\n","  # Security: to avoid that one of the triplets goes out of frame while the others don't --> would show pairs then blank then pairs\n","  # Thus, collect minimum number of frames before a shape goes out of the image, among the three batches \n","  min_count = min(counts)\n","\n","  # For this minimum number perform the \"fuzzy\" motion with alternating offset\n","  for j in range(min_count):\n","    final_motion_batch.append(motion_batches[j % 3][:,j,:,:,:])\n","  \n","  # Remaining frames are of the batch which has this minimum count\n","  index_min_count = counts.index(min_count)\n","  for j in range(min_count, n_frames):\n","    final_motion_batch.append(motion_batches[index_min_count][:,j,:,:,:])\n","  \n","  return tf.stack(final_motion_batch, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35NQBznT5slH","colab_type":"text"},"source":["Make motion batch for reconstruction (make_motion_batch) and for decoding (make_decoder_batch)"]},{"cell_type":"code","metadata":{"id":"ddqJdoppB1yc","colab_type":"code","cellView":"both","colab":{}},"source":["# Function returning a sequence of frames in which any sample move at a random speed\n","def make_motion_batch(batch_samples, r_vel, c_vel, before_blanks, after_blanks):\n","  '''\n","  Reconstruction motion\n","  batch_samples: reconstruction batch\n","  r_vel: x-speed\n","  c_vel: y-speed\n","  before_blanks: number of empty frames added to the mandatory empty frame before motion appears\n","  after_blanks: number of empty frames after motion\n","\n","  Returns: \n","  motion_batch (the 13 frames, 3 empty frames before and 10 motion frames)\n","  count: number of frames before a shape went out of bounds\n","  '''\n","  motion_batch   = []\n","  (row_0, col_0) = ((i-s)//2 for i, s in zip(im_dims[:-1], sample_dims[1:-1]))\n","  for sample in batch_samples:\n","    image = np.zeros(im_dims, dtype=np.uint8)\n","    image[row_0:row_0+sample_dims[1], col_0:col_0+sample_dims[2], :] = sample \n","    frames = [image]\n","    init_nnz = np.count_nonzero(image) # Number of non-zero pixels in the initial image (used to check if a shape goes out of bounds)\n","    frames, count = generateFrames(frames, image, n_frames, r_vel, c_vel, \n","                                   init_nnz, before_blanks, after_blanks)\n","    motion_batch.append(tf.stack(frames))\n","  return tf.stack(motion_batch), count\n","\n","def make_decoder_batch(batch_samples, n_verniers=1):\n","  '''\n","  Decoding motion, with only one vernier\n","  batch_samples: decoding batch\n","  n_verniers: the number of times the vernier will appear \n","  '''\n","  motion_batch = []\n","  (row_0, col_0) = ((i-s)//2 for i, s in zip(im_dims[:-1], sample_dims[:-1]))\n","  for sample in batch_samples:\n","    zeros = [np.zeros(im_dims) for i in range(n_frames)]\n","    image = np.zeros(im_dims, dtype=np.uint8)\n","    image[row_0:row_0+sample_dims[0], col_0:col_0+sample_dims[1], :] = sample\n","    r_vel = np.random.randint(0,2)*2-1 # X-speed\n","    c_vel = (1 if np.random.random() > 0.5 else -1)*np.random.randint(1,4) # Y-speed\n","    frames = [image]\n","    # Generate other frames\n","    # idx: number of frames before a line went out of bounds\n","    frames, idx = generateDecoderFrames(frames, image, n_frames, r_vel, c_vel, init_nnz=np.count_nonzero(image))\n","\n","    # Active_idx: the index of the frame that will be showed \n","    if (idx == 3):\n","      active_idx = 3\n","    else:\n","      active_idx = np.random.randint(3, idx)\n","    \n","    # If n_verniers = 1 or 5 => generate random idxs where the vernier will appear\n","    active_idxs = random.sample(range(3, n_frames), n_verniers)\n","\n","    # For selected indices, replace empty images by the selected frame\n","    for idx_frame in active_idxs:\n","      zeros[idx_frame] = frames[active_idx]\n","\n","    # Add noise\n","    zeros = [addNoise(frame) for frame in zeros]\n","    \n","    motion_batch.append(tf.stack(zeros))\n","  \n","  return tf.stack(motion_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOOZ07Unk9bO","colab_type":"code","cellView":"both","colab":{}},"source":["def make_decoder_batch2(batch_size, n_verniers=1):\n","  '''\n","  Decoder batch with two pairs of verniers\n","  batch_size: size of batch\n","  n_verniers: number of times the vernier pair will appear\n","\n","  Returns: motion batch for given batch size and corresponding labels at each frame for each motion batch\n","  '''\n","\n","  motion_batch = []\n","  motion_labels = []\n","  (row_0, col_0) = ((i-s)//2 for i, s in zip(im_dims[:-1], sample_dims[:-1]))\n","  for i in range(batch_size):\n","    zeros = [addNoise(np.zeros(im_dims)) for i in range(n_frames)]\n","    frames, labels, idx_vernier = generateTestSet2(im_dims)\n","    \n","    # Generate \"n_verniers\" idxs where the vernier will appear\n","    active_idxs = random.sample(range(3, n_frames), n_verniers)\n","\n","    # For selected indices, replace empty images by the selected frame\n","    for idx_frame in active_idxs:\n","      zeros[idx_frame] = frames[idx_vernier,:,:,:]\n","    \n","    motion_batch.append(tf.stack(zeros))\n","    motion_labels.append(labels[idx_vernier])\n","  \n","  return tf.stack(motion_batch), tf.stack(motion_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8hSCBuBB4-6","colab_type":"code","cellView":"both","colab":{}},"source":["# Core model zoo\n","simple_RNN = tf.keras.Sequential([\n","        tf.keras.layers.InputLayer(input_shape=(n_frames,) + im_dims),\n","        tf.keras.layers.Reshape((n_frames, tf.math.reduce_prod(im_dims))),\n","        tf.keras.layers.SimpleRNN(units=n_units, return_sequences=True)])  # w/o return_seq: returns output only at last step (= last frame)\n","\n","simple_LSTM = tf.keras.Sequential([\n","        tf.keras.layers.InputLayer(input_shape=(n_frames,) + im_dims),\n","        tf.keras.layers.Reshape((n_frames, tf.math.reduce_prod(im_dims))),\n","        tf.keras.layers.LSTM(units=n_units, return_sequences=True)])  # w/o return_seq: returns output only at last step (= last frame)\n","\n","simple_GRU = tf.keras.Sequential([\n","        tf.keras.layers.InputLayer(input_shape=(n_frames,) + im_dims),\n","        tf.keras.layers.Reshape((n_frames, tf.math.reduce_prod(im_dims))),\n","        tf.keras.layers.GRU(units=n_units, return_sequences=True)])  # w/o return_seq: returns output only at last step (= last frame)\n","\n","conv2D_LSTM = tf.keras.Sequential([\n","        tf.keras.layers.InputLayer(input_shape=(n_frames,) + im_dims),\n","        # tf.keras.layers.Reshape((n_frames, tf.math.reduce_prod(im_dims))),\n","        tf.keras.layers.ConvLSTM2D(filters=16, kernel_size=(16,16), strides = (2,2), return_sequences=True, stateful=False, padding='same'),\n","        tf.keras.layers.Reshape((n_frames, -1))\n","])\n","\n","class PredNet(tf.keras.Model):\n","  def __init__(self,  R_channels, A_channels, t_extrapolate=float('inf')):\n","    super(PredNet, self).__init__()\n","    self.r_channels    = R_channels + (0, )  # for convenience (last layer)\n","    self.a_channels    = A_channels\n","    self.n_layers      = len(R_channels)\n","    self.t_extrapolate = t_extrapolate\n","\n","    for i in range(self.n_layers):\n","      cell = tf.keras.layers.ConvLSTM2D(filters=self.r_channels[i], kernel_size=(3,3), return_sequences=True, stateful=True, padding='same')  # number of input features: 2*self.a_channels[i] + self.r_channels[i+1]\n","      setattr(self, 'cell{}'.format(i), cell)\n","\n","    for i in range(self.n_layers):\n","      conv = tf.keras.layers.Conv2D(filters=self.a_channels[i], kernel_size=(3,3), padding='same', activation='relu')\n","      if i == 0:\n","        conv = tf.keras.Sequential([conv, SatLU()])\n","      setattr(self, 'conv{}'.format(i), conv)\n","\n","    self.upsample = UpSampling2D(size=(2,2))\n","    self.maxpool  = MaxPool2D(pool_size=(2,2), strides=(2,2))\n","\n","    for l in range(self.n_layers - 1):\n","      update_A = tf.keras.Sequential([tf.keras.layers.Conv2D(self.a_channels[l+1], (3, 3), padding='same'), self.maxpool])\n","      setattr(self, 'update_A{}'.format(l), update_A)\n","\n","    # they used self.reset_parameters(), but here it is not needed?\n","  \n","  def set_t_extrapolate(self, t):\n","    self.t_extrapolate = t\n","\n","  def call(self, x):\n","    R_seq = [None] * self.n_layers\n","    H_seq = [None] * self.n_layers\n","    E_seq = [None] * self.n_layers\n","    state = [None] * self.n_layers\n","\n","    h, w       = x.shape[-3], x.shape[-2]\n","    batch_size = x.shape[0]\n","    time_steps = x.shape[1]\n","\n","    for l in range(self.n_layers):\n","      E_seq[l] = tf.zeros((batch_size,    h, w, 2*self.a_channels[l]))\n","      R_seq[l] = tf.zeros((batch_size, 1, h, w, 1*self.r_channels[l]))\n","      state[l] = tf.zeros((self.r_channels[l], self.r_channels[l]))\n","      w = w//2\n","      h = h//2\n","    \n","    frame_predictions = [[] for l in range(self.n_layers)]\n","    for t in range(time_steps):\n","\n","      # Top-down pass updating LSTM states (R is LSTM neural state)\n","      for l in reversed(range(self.n_layers)):\n","        cell = getattr(self, 'cell{}'.format(l))\n","        E    = tf.expand_dims(E_seq[l], axis=1)\n","        R    = R_seq[l]\n","        if l == self.n_layers - 1:\n","          R = cell(E)\n","        else:\n","          R = cell(tf.concat([E, tf.expand_dims(self.upsample(tf.squeeze(R_seq[l+1], axis=1)), axis=1)], axis=-1))\n","        R_seq[l] = R\n","\n","      # Bottom-up pass: first, compute predictions A_hat. Second, compute errors between predictions A_hat and frames A\n","      A = frame_predictions[0][-1] if t >= self.t_extrapolate else x[:,t]  # extrapolation will set forward input to zero\n","      for l in range(self.n_layers):\n","        conv     = getattr(self, 'conv{}'.format(l))\n","        A_hat    = conv(tf.squeeze(R_seq[l], axis=1))\n","        frame_predictions[l].append(A_hat)\n","        pos      = tf.nn.relu(A_hat - A)\n","        neg      = tf.nn.relu(A - A_hat)\n","        E        = tf.concat([pos, neg], axis=-1)\n","        E_seq[l] = E\n","        if l < self.n_layers - 1:\n","          update_A = getattr(self, 'update_A{}'.format(l))\n","          A        = update_A(E)\n","    \n","    return [tf.stack(frame_predictions[l], axis=1) for l in range(self.n_layers)]\n","\n","# Helper function for prednet\n","class SatLU(tf.keras.Model):\n","    def __init__(self, lower=0, upper=1):\n","        super(SatLU, self).__init__()\n","        self.lower = lower\n","        self.upper = upper\n","\n","    def call(self, input):\n","        return tf.clip_by_value(input, self.lower, self.upper)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1QjejE4ywhEE","colab_type":"text"},"source":["R2UNet (not used)"]},{"cell_type":"code","metadata":{"id":"UeNoAu8ZWxWf","colab_type":"code","cellView":"both","colab":{}},"source":["''' \n","Inspired by\n","https://github.com/zhixuhao/unet/blob/master/model.py\n","https://github.com/LeeJunHyun/Image_Segmentation/blob/master/network.py\n","'''\n","\n","class up_conv(tf.keras.Model):\n","  def __init__(self, filters):\n","    super(up_conv, self).__init__()\n","    self.up = tf.keras.Sequential([\n","        UpSampling2D(size=(2,2)),\n","        Conv2D(filters, kernel_size=(3,3), strides=(1,1), padding='same'),\n","        BatchNormalization(),\n","        tf.keras.layers.Activation('relu')\n","    ])\n","\n","  def call(self, x):\n","    x = self.up(x)\n","    return x\n","\n","class rec_block(tf.keras.Model):\n","  def __init__(self, filters, t=2):\n","    super(rec_block, self).__init__()\n","    self.t = t\n","    self.filters = filters\n","    self.conv = tf.keras.Sequential([\n","        Conv2D(filters, kernel_size=(3,3), strides=(1,1), padding='same'),\n","        BatchNormalization(),\n","        tf.keras.layers.Activation('relu')\n","    ])\n","\n","  def call(self, x):\n","    for i in range(self.t):\n","      if i==0:\n","        x1 = self.conv(x)\n","      \n","      x1 = self.conv(x+x1)\n","    return x1\n","\n","class RRCNN_block(tf.keras.Model):\n","  def __init__(self, filters, t=2):\n","    super(RRCNN_block, self).__init__()\n","    self.RCNN = tf.keras.Sequential([\n","        rec_block(filters, t),\n","        rec_block(filters, t)\n","    ])\n","    \n","    self.conv11 = Conv2D(filters, kernel_size=(1,1), strides=(1,1), padding='same')\n","\n","  def call(self, x):\n","    x = self.conv11(x)\n","    x1 = self.RCNN(x)\n","    return x+x1\n","\n","class R2UNet(tf.keras.Model):\n","  def __init__(self, depth=3):\n","    super(R2UNet, self).__init__()\n","\n","    self.maxpool = MaxPool2D(pool_size=(2,2), strides=(2,2))\n","    self.depth = depth\n","    self.conv11 = Conv2D(1, kernel_size=(1,1), strides=(1,1), padding='same', activation='sigmoid')\n","    \n","  def call(self, inputs):\n","    time_steps = inputs.shape[1]\n","    preds = []\n","    for t in range(time_steps):\n","      x = inputs[:,t]\n","      filters = 64\n","      for j in range(self.depth):\n","        x = RRCNN_block(filters)(x)\n","        x = self.maxpool(x)\n","        filters *= 2\n","\n","      x = RRCNN_block(filters)(x)\n","      \n","      for k in reversed(range(self.depth)):\n","        filters = filters // 2\n","        x = up_conv(filters)(x)\n","        x = RRCNN_block(filters)(x)\n","      \n","      out = self.conv11(x)\n","      preds.append(out)\n","    \n","    return tf.stack(preds, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEnNOqVZCLVM","colab_type":"code","colab":{}},"source":["# Reconstructor and decoder\n","\n","my_recons = tf.keras.Sequential(\n","    [\n","        tf.keras.layers.Dense(4*8*32),\n","        tf.keras.layers.Reshape((4,8,32)),\n","        tf.keras.layers.Conv2DTranspose(16, (5,5), strides=(1,1), padding='same', activation='relu'),\n","        tf.keras.layers.Conv2DTranspose( 8, (5,5), strides=(2,2), padding='same', activation='relu'),\n","        tf.keras.layers.Conv2DTranspose( 4, (5,5), strides=(2,2), padding='same', activation='relu'),\n","        tf.keras.layers.Conv2DTranspose( 1, (5,5), strides=(2,2), padding='same', activation='relu')\n","    ]\n",")\n","\n","my_decoder = tf.keras.Sequential(\n","    [\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        tf.keras.layers.Dense(2, activation='softmax')\n","    ]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELs9WGQUCO0X","colab_type":"code","cellView":"both","colab":{}},"source":["# Wrapper\n","# Class to combine core model, reconstructor and decoder\n","\n","class Wrapper(tf.keras.Model):\n","  def __init__(self, model, reconstructor, decoder):\n","    super(Wrapper, self).__init__()\n","    self.model         = model\n","    self.reconstructor = reconstructor\n","    self.decoder       = decoder\n","  \n","  def call(self, img):\n","    x      = tf.tile(tf.expand_dims(img, axis=1), (1, n_frames, 1, 1, 1))\n","    states = self.model(x)\n","    return self.decoder(states[:,0])\n","    \n","  def get_reconstructions(self, x):\n","    if isinstance(self.model, PredNet):\n","      return self.model(x)[0]\n","    else:\n","      x = tf.cast(x, tf.float32)\n","      states = self.model(x)\n","      recs   = []\n","      for t in range(n_frames):\n","        recs.append(self.reconstructor(states[:,t])) \n","      return tf.stack(recs, axis=1)\n","\n","  def get_predictions(self, x):\n","    if isinstance(self.model, PredNet):\n","      states = self.model(x)[-1]  # we decode from the top (most latent) layer\n","    elif isinstance(self.model, R2UNet):\n","      states = self.model(x)\n","    else:\n","      states = self.model(x)      # we decode from the whole output\n","    preds = []\n","    for t in range(n_frames):\n","      preds.append(self.decoder(states[:,t]))\n","    return tf.stack(preds, axis=1)\n","  \n","  def rec_loss(self, x, recons):\n","    n_frames = x.shape[1]\n","    recons   = tf.cast(recons, tf.float32)\n","    weights  = [1.0/(n+1) for n in range(n_frames)]\n","    if isinstance(self.model, PredNet):  # PredNet n_th output is the prediction of the n_th frame\n","      if self.model.t_extrapolate < float('inf'):\n","        weights = [w if n < self.model.t_extrapolate else 2.0*w for n, w in enumerate(weights)]\n","      losses = [w*tf.reduce_sum((recons[:,n] - x[:,n])**2) for n, w in enumerate(weights)]\n","    elif isinstance(self.model, R2UNet):\n","      x = tf.cast(x, tf.float32)\n","      losses = [w*tf.reduce_sum((recons[:,n] - x[:,n])**2) for n, w in enumerate(weights)]\n","    else:\n","      x = tf.cast(x, tf.float32)\n","      losses = [w*tf.reduce_sum((recons[:,n-1] - x[:,n])**2) for n, w in enumerate(weights)]\n","    return tf.reduce_sum(losses)\n","  \n","  def pred_loss(self, labels, predictions):\n","    n_frames    = labels.shape[1]\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","    losses      = [loss_object(labels[:,n], predictions[:,n]) for n in range(n_frames)]\n","    \n","    return tf.reduce_sum(losses), losses\n","\n","  def pred_test_loss(self, labels, predictions):\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","    losses = []\n","    dominances = []\n","    for n in range(3, n_frames):\n","      print(predictions[0,n])\n","      \n","      losses.append(loss_object(labels[:,0], predictions[:,n]))\n","      dominances.append(int(labels[0,3].numpy() == tf.argmax(predictions[0,n]).numpy()))\n","\n","    print('CV dominance: ', dominances)\n","    return tf.reduce_sum(losses), losses, dominances\n","\n","  def train_step(self, x, b, e, opt, labels=None, train_reconstructions=False):\n","    with tf.GradientTape() as tape:\n","      x = tf.cast(x, tf.float32)\n","      if train_reconstructions:\n","        recs = self.get_reconstructions(x)\n","        loss = self.rec_loss(x, recs)\n","        if isinstance(self.model, PredNet):\n","          vars_to_train = self.model.trainable_variables\n","        elif isinstance(self.model, R2UNet):\n","          vars_to_train = self.model.trainable_variables\n","        else:\n","          vars_to_train = self.model.trainable_variables + self.reconstructor.trainable_variables\n","      else:\n","        preds              = self.get_predictions(x)\n","        loss, frame_losses = self.pred_loss(labels, preds)\n","        vars_to_train      = self.decoder.trainable_variables\n","      grad = tape.gradient(loss, vars_to_train)\n","      opt.apply_gradients(zip(grad, vars_to_train))\n","      if b == 0:\n","        print('\\nStarting epoch %3i with loss = %5.2f' % (e, loss))\n","        self.plot_output(x)\n","      return loss\n","  \n","  def lr_finder(self, batch_size, mode='reconstruct'):\n","    n_steps   = 100\n","    lrs       = np.logspace(-7, 1, num=n_steps)\n","    loss_list = []\n","    for e, lr in enumerate(lrs):\n","      print('\\rLR finder running %2i %%' % (e*100.0/n_steps,), end='')\n","      this_opt = tf.keras.optimizers.Adam(lr)\n","      mod_e    = int(e % ((n_samples/batch_size)-1))\n","      if mode == 'reconstruct':\n","        batch    = make_motion_batch(train_images[mod_e*batch_size:(mod_e+1)*batch_size])\n","        batch_labels = tf.tile(tf.expand_dims(train_labels[mod_e*batch_size:(mod_e+1)*batch_size], axis=-1), (1,n_frames))\n","      else:\n","        batch, labels    = make_decoder_batch2(32,n_verniers=5)\n","        batch_labels = tf.tile(tf.expand_dims(labels, axis=-1), (1,n_frames))\n","      loss_list.append(self.train_step(batch, 1, e, this_opt, train_reconstructions=True) if mode == 'reconstruct' else self.train_step(batch, 1, e, this_opt, labels=batch_labels, train_reconstructions=False))\n","    guess_index = tf.argmin(loss_list).numpy()-10\n","    lr_guess    = lrs[guess_index]\n","    fig, ax     = plt.subplots()\n","    ax.plot(lrs, loss_list)\n","    ax.set_xscale('log')\n","    ax.scatter(lrs[guess_index], loss_list[guess_index].numpy())\n","    plt.show()\n","    return lr_guess\n","\n","  def plot_output(self, x):\n","    # Plot frames\n","    r = self.get_reconstructions(x)\n","    p = self.get_predictions(x)\n","    f = plt.figure(figsize=(int(n_frames*(im_dims[1]+3)/32),int(2*(im_dims[0]+3)/32)))\n","    ref_pred = tf.argmax(p[0,0]).numpy()\n","    for t in range(n_frames):\n","      ax1 = f.add_subplot(2, n_frames+1, 0*(n_frames+1) + t + 1)\n","      ax2 = f.add_subplot(2, n_frames+1, 1*(n_frames+1) + t + 1)\n","      #print(p[0,t].numpy())\n","      ax2.set_title('Pred: %2i' % (tf.argmax(p[0,t]).numpy(), ))\n","      ax1.imshow(x[0,t,:,:,0])\n","      ax2.imshow(r[0,t,:,:,0])\n","    plt.show()\n","\n","    # gif_frame [featuremap_n] = network.layers[minus2].output[:,:,n]\n","    # Plot gifs\n","    template  = 0.25*tf.ones((10 if i == 3 else x.shape[i] for i in range(len(x.shape))))  # just a gray rectangle\n","    xr        = tf.concat((x, template, r), axis=3)                   # concatenate along the columns dimension\n","    xr_frames = [(255.0*xr[0,t,:,:,0].numpy().clip(min=0, max=255)).astype(np.uint8) for t in range(n_frames)]\n","    imageio.mimsave('./xr.gif', xr_frames, duration=0.1)\n","    with open('./xr.gif','rb') as f:\n","      display(Image(data=f.read(), format='png', width=4*xr_frames[0].shape[1], height=4*xr_frames[0].shape[0]))\n","\n","  def get_occlusion(self, image, model, label, patch_size):\n","    explainer = OcclusionSensitivity()\n","    occlu_img = explainer.explain((image, label), model, label, patch_size)\n","    plt.figure()\n","    plt.imshow(image[0,:,:,0])\n","    plt.imshow(occlu_img, alpha=.5)\n","    plt.show()\n","\n","  def get_gradCAM(self, image, model, layer_name, label):\n","    explainer = GradCAM()\n","    grad_img  = explainer.explain((image, label), model, layer_name, label)\n","    plt.figure()\n","    plt.imshow(image[0,:,:,0])\n","    plt.imshow(grad_img, alpha=.5)\n","    plt.show()\n","  \n","  def plot_neuron_heatmap(self, input_sequence, state_sequence):\n","    # Input sequence: imgs\n","    # State sequence: self.model(x), states of model (e.g., last layer before output layer, must be convolutional)\n","    input_sequence = np.array(input_sequence)\n","    input_sequence = np.pad(input_sequence, ((0, 0), (16,16), (0,0), (0,0)) )\n","    print('Input seq: ', input_sequence.shape)\n","    print('State seq: ', state_sequence.shape)\n","    im_side = input_sequence.shape[-2] # 64\n","    n_timesteps = n_frames\n","    state_sequence = [resize(state_sequence[t], (im_side, im_side)) for t in range(n_timesteps)]\n","    state_sequence = np.array(state_sequence)\n","    mean_state_sequence = np.mean(state_sequence, axis=-1)\n","    n_channels = state_sequence.shape[-1]\n","\n","    norm = np.max(state_sequence)\n","\n","    state_sequence /= norm\n","\n","    n_rows = int(np.ceil(np.sqrt(n_channels+2)))\n","    gap_size = 5\n","    out_im_side = n_rows*(im_side+gap_size)\n","    out_seq = np.zeros((n_timesteps, out_im_side, out_im_side))\n","    for t in range(n_timesteps):\n","        for c in range(n_channels+1):\n","            if c == 0:\n","                out_seq[t, :im_side, :im_side] = np.squeeze(input_sequence[t])\n","            elif c == 1:\n","                out_seq[t, im_side+gap_size:2*im_side+gap_size, im_side+gap_size:2*im_side+gap_size] = np.squeeze(mean_state_sequence[t])\n","            else:\n","                row_pos = int(((c*(im_side+gap_size))//out_im_side)*(im_side+gap_size))\n","                col_pos = int((c*(im_side+gap_size))%out_im_side)\n","                out_seq[t, row_pos:row_pos+im_side, col_pos:col_pos+im_side] = np.squeeze(state_sequence[t, :, :, :])\n","                #print(state_sequence.shape)\n","                #for PredNet\n","                #out_seq[t, row_pos:row_pos+im_side, col_pos:col_pos+im_side] = np.squeeze(state_sequence[t, :, :, c-2])\n","    frames = [resize((255.0 * out_seq[t, :, :]), (out_im_side, out_im_side)).astype(np.uint8) for t in range(n_timesteps)]\n","    imageio.mimsave('./input_and_full_state_sequence.gif', frames, duration=0.333333)\n","    with open('./input_and_full_state_sequence.gif','rb') as f:\n","      display(Image(data=f.read(), format='png', width=out_im_side, height=out_im_side))\n","  \n","  def stats(self, batch, statFunc, **kwargs):\n","    '''\n","    Perform stats for each model (during testing)\n","    batch: current batch\n","    statFunc: function of interest (variance or entropy)\n","    kwargs: arguments necessary for certain stat functions\n","    '''\n","\n","    # loi = layer of interest = the layer before the output layer\n","    if isinstance(self.model, PredNet):\n","      loi = self.model(batch)[-2]\n","    else:\n","      loi = self.model.layers[-2](batch)\n","\n","    stats = []\n","\n","    # Perform stats on frames after the 3 blank ones\n","    \n","    for i in range(3,n_frames):\n","      loi_ = tf.keras.backend.flatten(loi[:,i,:,:,:])\n","\n","      if statFunc == entropy:\n","        # For entropy calculations, need to normalize the values between 0 and 1 \n","        # (to have \"probabilities\")\n","        # S = -sum(pk*log(pk))\n","        max_ = tf.math.reduce_max(loi_)\n","        min_ = tf.math.reduce_min(loi_)\n","        \n","        loi_ = (loi_+np.finfo(float).eps-min_)/(max_-min_)\n","\n","      stats.append(statFunc(loi_, **kwargs))\n","\n","    return stats"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECt0gjJ58Qgs","colab_type":"text"},"source":["Learning rate finder"]},{"cell_type":"code","metadata":{"id":"sfcLaZsW5aS-","colab_type":"code","outputId":"7c62af86-ab3e-42d9-8456-5559c69e5da1","executionInfo":{"status":"ok","timestamp":1578563651235,"user_tz":-60,"elapsed":88704,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":371}},"source":["n_epochs = 300\n","data_list = generateReconsDataset(im_dims)\n","train_images, test_images = split_data(data_list)\n","\n","n_samples = train_images.shape[0]\n","sample_dims = train_images[0].shape\n","\n","# Training parameters\n","batch_size = 16\n","n_batches  = 16\n","learn_rate = 3e-4\n","\n","# Networks (note: PredNet does not use my_recons, because it produces reconstructions itself)\n","# my_model, model_name = PredNet((1, 32, 64), (1, 32, 64)), 'large_prednet' \n","# my_model, model_name = PredNet((1, 8, 16), (1, 8, 16)), 'large_prednet_2' \n","# my_model, model_name = conv2D_LSTM, 'conv2D_lstm'\n","# my_model, model_name = simple_RNN, 'simple_RNN'\n","# my_model, model_name = simple_LSTM, 'simple_lstm'\n","# my_model, model_name = R2UNet(), 'R2Unet'\n","my_model, model_name = simple_GRU, 'large_gru'\n","wrap = Wrapper(my_model, my_recons, my_decoder)\n","\n","# Uncomment the 3 lines below to select the best learning rate, then comment and run again\n","learn_rate = wrap.lr_finder(batch_size, mode='decoder')\n","print(learn_rate)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Circles: 2500, Diamonds: 2500, Triangles: 2500, Lines: 2500, Total: 10000\n","Whole dataset dimensions:  (10000, 3, 32, 64, 1)\n","Training dataset dimensions:  (8500, 3, 32, 64, 1)\n","Test dataset dimensions:  (1500, 3, 32, 64, 1)\n","LR finder running 99 %"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd0lqkOMuSQ36F590dDtdseOgAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0.5094138014816385\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4mFUXOo8-ag3","colab_type":"text"},"source":["Reconstruction training"]},{"cell_type":"code","metadata":{"id":"nUikV9PFCROS","colab_type":"code","cellView":"both","colab":{}},"source":["n_epochs = 300\n","data_list = generateReconsDataset(im_dims)\n","train_images, test_images = split_data(data_list)\n","\n","n_samples = train_images.shape[0]\n","sample_dims = train_images[0].shape\n","\n","# Training parameters\n","batch_size = 16\n","n_batches  = 16\n","learn_rate = 2e-3\n","\n","# Networks (note: PredNet does not use my_recons, because it produces reconstructions itself)\n","my_model, model_name = PredNet((1, 32, 64), (1, 32, 64)), 'large_prednet' \n","# my_model, model_name = PredNet((1, 8, 16), (1, 8, 16)), 'large_prednet_2' \n","# my_model, model_name = conv2D_LSTM, 'conv2D_lstm'\n","# my_model, model_name = simple_RNN, 'simple_RNN'\n","# my_model, model_name = simple_LSTM, 'simple_lstm'\n","# my_model, model_name = R2UNet(), 'R2Unet'\n","# my_model, model_name = simple_GRU, 'large_gru'\n","wrap = Wrapper(my_model, my_recons, my_decoder)\n","\n","# Uncomment the 3 lines below to select the best learning rate, then comment and run again\n","# learn_rate = wrap.lr_finder(batch_size, mode='reconstruct')\n","# print(learn_rate)\n","# a = 1./0.\n","opt = tf.keras.optimizers.Adam(learn_rate)\n","\n","# Checkpoint (save and load model weights) \n","mckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_model)\n","mmanager = tf.train.CheckpointManager(mckpt, './gdrive/My Drive/LabImm/' + model_name + '/mckpt', max_to_keep=1)\n","mckpt.restore(mmanager.latest_checkpoint)\n","rckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_recons)\n","rmanager = tf.train.CheckpointManager(rckpt, './gdrive/My Drive/LabImm/' + model_name +'/rckpt', max_to_keep=1)\n","rckpt.restore(rmanager.latest_checkpoint)\n","dckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_decoder)\n","dmanager = tf.train.CheckpointManager(dckpt, './gdrive/My Drive/LabImm/' + model_name + '/dckpt', max_to_keep=1)\n","dckpt.restore(dmanager.latest_checkpoint)\n","\n","print(mckpt.step)\n","\n","losses = np.zeros((n_epochs, 1))\n","\n","# Training loop for the reconstruction part\n","train_reconstructions = True\n","if train_reconstructions:\n","  for e in range(n_epochs):\n","    mod_e      = int(e % (n_samples/(batch_size*n_batches)-1))\n","    epoch_imgs = train_images[mod_e:mod_e+batch_size*n_batches]\n","    for b in range(n_batches):\n","      batch_imgs = make_fuzzy_motion_batch(epoch_imgs[b*batch_size:(b+1)*batch_size])\n","      loss = wrap.train_step(batch_imgs, b, rckpt.step, opt, None, train_reconstructions)\n","      if (b == 0):\n","        losses[e] = loss.numpy()\n","        # To plot heatmap\n","        '''if (e % 10 == 0):\n","          wrap.plot_neuron_heatmap(batch_imgs[0,:,:,:,:], wrap.model(batch_imgs)[-1][0])'''\n","      # wrap.model.reset_states() --> seems to alter learning\n","    rckpt.step.assign_add(1)\n","    mckpt.step.assign_add(1)\n","    if int(rckpt.step) % 10 == 0:\n","      np.savetxt('./gdrive/My Drive/LabImm/' + model_name + 'new_losses' + str(e) + '.txt', losses)\n","      if e > 10:\n","        os.remove('./gdrive/My Drive/LabImm/' + model_name + 'new_losses' + str(e-10) + '.txt')\n","      \n","      save_path = mmanager.save()\n","      print(\"Saved checkpoints for step {}: {}\".format(int(mckpt.step), save_path))\n","      save_path = rmanager.save()\n","      print(\"Saved checkpoints for step {}: {}\".format(int(rckpt.step), save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3jm2YYat-sIZ","colab_type":"text"},"source":["Decoder training"]},{"cell_type":"code","metadata":{"id":"S7eBw0B6D6ls","colab_type":"code","cellView":"both","colab":{}},"source":["n_epochs = 300\n","d_losses = np.zeros((n_epochs))\n","decoder_list, decoder_labels, _ = generateDecoderDataset(im_dims)\n","train_images, test_images, train_labels, test_labels = split_data(decoder_list, decoder_labels)\n","\n","n_samples = train_images.shape[0]\n","sample_dims = train_images[0].shape\n","\n","# Training parameters\n","batch_size = 16\n","n_batches  = 16\n","learn_rate = 2e-3\n","\n","# Networks (note: PredNet does not use my_recons, because it produces reconstructions itself)\n","my_model, model_name = PredNet((1, 32, 64), (1, 32, 64)), 'large_prednet'\n","# my_model, model_name = PredNet((1, 8, 16), (1, 8, 16)), 'large_prednet_2'  \n","# my_model, model_name = conv2D_LSTM, 'conv2D_lstm'\n","# my_model, model_name = simple_RNN, 'simple_RNN'\n","# my_model, model_name = simple_LSTM, 'simple_lstm'\n","# my_model, model_name = simple_GRU, 'simple_gru'\n","wrap = Wrapper(my_model, my_recons, my_decoder)\n","\n","# Uncomment the 3 lines below to select the best learning rate, then comment and run again\n","#learn_rate = wrap.lr_finder(batch_size, mode='decoder')\n","#print(learn_rate)\n","#a = 1./0.\n","opt = tf.keras.optimizers.Adam(learn_rate)\n","\n","# Checkpoint (save and load model weights) \n","mckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_model)\n","mmanager = tf.train.CheckpointManager(mckpt, './gdrive/My Drive/LabImm/' + model_name + '/mckpt', max_to_keep=1)\n","mckpt.restore(mmanager.latest_checkpoint)\n","rckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_recons)\n","rmanager = tf.train.CheckpointManager(rckpt, './gdrive/My Drive/LabImm/' + model_name + '/rckpt', max_to_keep=1)\n","rckpt.restore(rmanager.latest_checkpoint)\n","dckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_decoder)\n","dmanager = tf.train.CheckpointManager(dckpt, './gdrive/My Drive/LabImm/' + model_name + '/dckpt2', max_to_keep=1)\n","dckpt.restore(dmanager.latest_checkpoint)\n","\n","print(mckpt.step)\n","print(dckpt.step)\n","\n","'''if (int(dckpt.step) != 0):\n","  epoch = int(dckpt.step)\n","  print('Found checkpoint at epoch: ' + repr(epoch))\n","  filename = './gdrive/My Drive/' + model_name + '/' + model_name + '_dlosses' + str(epoch-1) + '.txt'\n","  losses = np.loadtxt(filename, dtype='float')\n","else:\n","  losses = np.zeros((n_epochs, 1))'''\n","\n","losses = np.zeros((n_epochs, 1))\n","\n","# Training loop for the decoding part\n","train_decoder = True\n","if train_decoder:\n","  for e in range(n_epochs):\n","    mod_e      = int(e % (n_samples/(batch_size*n_batches)-1))\n","    epoch_imgs = train_images[mod_e:mod_e+batch_size*n_batches]\n","    epoch_labels = train_labels[mod_e:mod_e+batch_size*n_batches]\n","    for b in range(n_batches):\n","      if (random.random() < 0.5):\n","        batch, labels = make_decoder_batch2(16, n_verniers=5)\n","        batch_labels = tf.tile(tf.expand_dims(labels, axis=-1), (1,n_frames))\n","      else:\n","        batch = make_decoder_batch(epoch_imgs[b*batch_size:(b+1)*batch_size], n_verniers=5)\n","        batch_labels = tf.tile(tf.expand_dims(epoch_labels[b*batch_size:(b+1)*batch_size], axis=-1), (1,n_frames))\n","      loss = wrap.train_step(batch, b, dckpt.step, opt, batch_labels, train_reconstructions=False)\n","      if (b == 0):\n","        losses[e] = loss.numpy()\n","        # To plot heatmap\n","        '''if (e % 10 == 0):\n","          wrap.plot_neuron_heatmap(batch[0,:,:,:,:], wrap.model(batch)[-1][0])'''\n","      #wrap.model.reset_states()''' --> seems to alter learning\n","    dckpt.step.assign_add(1)\n","    if int(dckpt.step) % 10 == 0:\n","      np.savetxt('./gdrive/My Drive/LabImm/' + model_name + '_d_losses' + str(e) + '.txt', losses)\n","      if e > 10:\n","        os.remove('./gdrive/My Drive/LabImm/' + model_name + '_d_losses' + str(e-10) + '.txt')\n","      \n","      save_path = dmanager.save()\n","      print(\"Saved checkpoints for step {}: {}\".format(int(dckpt.step), save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBPjVmmdFIk_","colab_type":"text"},"source":["Testing"]},{"cell_type":"code","metadata":{"id":"DXDiU-qJmmLX","colab_type":"code","outputId":"bb7e801d-044f-40a3-b790-ac8026cf6bad","executionInfo":{"status":"ok","timestamp":1578759517962,"user_tz":-60,"elapsed":202585,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["n_epochs = 100\n","\n","n_frames = 13\n","\n","# Networks (note: PredNet does not use my_recons, because it produces reconstructions itself)\n","my_model, model_name = PredNet((1, 32, 64), (1, 32, 64)), 'large_prednet' \n","# my_model, model_name = conv2D_LSTM, 'conv2D_lstm'\n","# my_model, model_name = simple_RNN, 'simple_RNN'\n","# my_model, model_name = simple_LSTM, 'simple_lstm'\n","# my_model, model_name = simple_GRU, 'large_gru'\n","wrap = Wrapper(my_model, my_recons, my_decoder)\n","\n","learn_rate = 3e-4\n","batch_size = 1\n","\n","# Uncomment the 3 lines below to select the best learning rate, then comment and run again\n","#learn_rate = wrap.lr_finder(batch_size, mode='decoder')\n","#print(learn_rate)\n","#a = 1./0.\n","opt = tf.keras.optimizers.Adam(learn_rate)\n","\n","# Checkpoint (save and load model weights) \n","mckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_model)\n","mmanager = tf.train.CheckpointManager(mckpt, './gdrive/My Drive/LabImm/' + model_name + '/mckpt', max_to_keep=1)\n","mckpt.restore(mmanager.latest_checkpoint)\n","rckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_recons)\n","rmanager = tf.train.CheckpointManager(rckpt, './gdrive/My Drive/LabImm/' + model_name + '/rckpt', max_to_keep=1)\n","rckpt.restore(rmanager.latest_checkpoint)\n","dckpt    = tf.train.Checkpoint(step=tf.Variable(0), optimizer=opt, net=my_decoder)\n","dmanager = tf.train.CheckpointManager(dckpt, './gdrive/My Drive/LabImm/' + model_name + '/dckpt2', max_to_keep=1)\n","dckpt.restore(dmanager.latest_checkpoint)\n","\n","print(dckpt.step)\n","\n","all_dominances = []\n","thresh_dominances = []\n","entropies, zscores, variances = [], [], []\n","b = 0\n","\n","variance_thresh = 0.03 # For now, arbitrary value\n","\n","# Training loop for the decoding part\n","test_decoder = True\n","if test_decoder:\n","  for e in range(n_epochs):\n","    # Create empty frames (default label = True)\n","    init_batch = tf.stack([addNoise(np.zeros(im_dims)) for i in range(3)])\n","    init_labels = tf.stack([True for i in range(3)])\n","\n","    # SQM generation\n","    batch, batch_labels = generateTestSet(im_dims, case='vav')\n","\n","    # Concatenate frames and labels\n","    batch = tf.concat([init_batch, batch],0)\n","    batch_labels = tf.concat([init_labels, batch_labels],0)\n","    \n","    assert(batch.shape[0] == 13)\n","\n","    batch = tf.tile(tf.expand_dims(batch, axis=0), (batch_size, 1, 1, 1, 1))\n","    batch = tf.cast(batch, dtype=tf.float32)\n","    batch_labels = tf.tile(tf.expand_dims(batch_labels, axis=0), (batch_size, 1))\n","    # Get label predictions\n","    preds = wrap.get_predictions(batch)\n","\n","    # Need to reset states between two calls of the model\n","    # Get entropies\n","    wrap.model.reset_states()\n","    entropies.append(wrap.stats(batch, entropy))\n","\n","    # Get variances\n","    wrap.model.reset_states()\n","    variances.append(wrap.stats(batch, moment, moment=2))\n","\n","    loss, frame_losses, dominances = wrap.pred_test_loss(batch_labels, preds)\n","    all_dominances.append(dominances)\n","    print('\\nStarting epoch %3i with loss = %5.2f' % (e, loss))\n","    wrap.model.reset_states()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=300>\n","tf.Tensor([0.652083   0.34791705], shape=(2,), dtype=float32)\n","tf.Tensor([0.46595937 0.53404063], shape=(2,), dtype=float32)\n","tf.Tensor([0.04512329 0.9548767 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.1728372 0.8271628], shape=(2,), dtype=float32)\n","tf.Tensor([0.00266515 0.9973348 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7491719 0.2508281], shape=(2,), dtype=float32)\n","tf.Tensor([0.9021361  0.09786391], shape=(2,), dtype=float32)\n","tf.Tensor([0.73180723 0.2681928 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.4274675  0.57253253], shape=(2,), dtype=float32)\n","tf.Tensor([0.9990005  0.00099954], shape=(2,), dtype=float32)\n","CV dominance:  [0, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch   0 with loss = 14.41\n","tf.Tensor([0.27947766 0.72052234], shape=(2,), dtype=float32)\n","tf.Tensor([0.47848046 0.5215196 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.102451   0.89754903], shape=(2,), dtype=float32)\n","tf.Tensor([0.19061476 0.80938524], shape=(2,), dtype=float32)\n","tf.Tensor([0.05651632 0.9434837 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.83812845 0.16187157], shape=(2,), dtype=float32)\n","tf.Tensor([0.9487808  0.05121926], shape=(2,), dtype=float32)\n","tf.Tensor([0.7633111  0.23668891], shape=(2,), dtype=float32)\n","tf.Tensor([0.5968519 0.4031481], shape=(2,), dtype=float32)\n","tf.Tensor([9.997522e-01 2.477300e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch   1 with loss = 16.80\n","tf.Tensor([0.36385152 0.6361485 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5836707  0.41632938], shape=(2,), dtype=float32)\n","tf.Tensor([0.18791644 0.81208354], shape=(2,), dtype=float32)\n","tf.Tensor([0.41370374 0.5862962 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01626856 0.9837315 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.87294185 0.12705813], shape=(2,), dtype=float32)\n","tf.Tensor([0.7006295  0.29937053], shape=(2,), dtype=float32)\n","tf.Tensor([0.40271097 0.597289  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.22122347 0.77877647], shape=(2,), dtype=float32)\n","tf.Tensor([0.99874437 0.00125557], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch   2 with loss = 12.80\n","tf.Tensor([0.12906186 0.8709381 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.26327127 0.73672867], shape=(2,), dtype=float32)\n","tf.Tensor([0.06502803 0.934972  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.13873939 0.86126065], shape=(2,), dtype=float32)\n","tf.Tensor([4.1520217e-04 9.9958485e-01], shape=(2,), dtype=float32)\n","tf.Tensor([0.7980193  0.20198075], shape=(2,), dtype=float32)\n","tf.Tensor([0.9401031  0.05989683], shape=(2,), dtype=float32)\n","tf.Tensor([0.84415483 0.15584514], shape=(2,), dtype=float32)\n","tf.Tensor([0.8015691  0.19843093], shape=(2,), dtype=float32)\n","tf.Tensor([9.998425e-01 1.574726e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch   3 with loss = 17.31\n","tf.Tensor([0.46181458 0.5381854 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.08734293 0.9126571 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.25067818 0.7493218 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.36874938 0.6312506 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.1079712  0.89202875], shape=(2,), dtype=float32)\n","tf.Tensor([0.88477844 0.11522157], shape=(2,), dtype=float32)\n","tf.Tensor([0.8851409  0.11485904], shape=(2,), dtype=float32)\n","tf.Tensor([0.1219664 0.8780336], shape=(2,), dtype=float32)\n","tf.Tensor([0.26817852 0.7318215 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.98923117 0.01076879], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch   4 with loss = 10.87\n","tf.Tensor([0.15466776 0.84533226], shape=(2,), dtype=float32)\n","tf.Tensor([0.7887397  0.21126024], shape=(2,), dtype=float32)\n","tf.Tensor([0.50392914 0.49607086], shape=(2,), dtype=float32)\n","tf.Tensor([0.18215117 0.81784886], shape=(2,), dtype=float32)\n","tf.Tensor([0.01670446 0.9832955 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5348067  0.46519333], shape=(2,), dtype=float32)\n","tf.Tensor([0.9744051  0.02559483], shape=(2,), dtype=float32)\n","tf.Tensor([0.75811553 0.24188448], shape=(2,), dtype=float32)\n","tf.Tensor([0.4438975 0.5561025], shape=(2,), dtype=float32)\n","tf.Tensor([0.99858093 0.00141912], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch   5 with loss = 15.64\n","tf.Tensor([0.11765981 0.88234025], shape=(2,), dtype=float32)\n","tf.Tensor([0.24333034 0.7566697 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.19208896 0.80791104], shape=(2,), dtype=float32)\n","tf.Tensor([0.26941416 0.7305859 ], shape=(2,), dtype=float32)\n","tf.Tensor([2.5353322e-04 9.9974650e-01], shape=(2,), dtype=float32)\n","tf.Tensor([0.7159019 0.2840981], shape=(2,), dtype=float32)\n","tf.Tensor([0.8439624  0.15603767], shape=(2,), dtype=float32)\n","tf.Tensor([0.7255982  0.27440184], shape=(2,), dtype=float32)\n","tf.Tensor([0.52605104 0.4739489 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.996020e-01 3.980385e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch   6 with loss = 13.92\n","tf.Tensor([0.38351125 0.61648875], shape=(2,), dtype=float32)\n","tf.Tensor([0.7935184  0.20648156], shape=(2,), dtype=float32)\n","tf.Tensor([0.08120893 0.918791  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.1919234 0.8080766], shape=(2,), dtype=float32)\n","tf.Tensor([0.00346808 0.99653184], shape=(2,), dtype=float32)\n","tf.Tensor([0.92470676 0.07529318], shape=(2,), dtype=float32)\n","tf.Tensor([0.8531403  0.14685963], shape=(2,), dtype=float32)\n","tf.Tensor([0.6136688  0.38633123], shape=(2,), dtype=float32)\n","tf.Tensor([0.5255118  0.47448817], shape=(2,), dtype=float32)\n","tf.Tensor([9.997118e-01 2.882226e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch   7 with loss = 16.72\n","tf.Tensor([0.11912357 0.8808764 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15380684 0.84619313], shape=(2,), dtype=float32)\n","tf.Tensor([0.2963014 0.7036986], shape=(2,), dtype=float32)\n","tf.Tensor([0.14436562 0.8556344 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03509141 0.96490854], shape=(2,), dtype=float32)\n","tf.Tensor([0.47164947 0.52835053], shape=(2,), dtype=float32)\n","tf.Tensor([0.9436344  0.05636563], shape=(2,), dtype=float32)\n","tf.Tensor([0.15138042 0.8486196 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7986551  0.20134494], shape=(2,), dtype=float32)\n","tf.Tensor([9.9948525e-01 5.1474490e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n","\n","Starting epoch   8 with loss = 13.69\n","tf.Tensor([0.5878016  0.41219845], shape=(2,), dtype=float32)\n","tf.Tensor([0.46192873 0.5380713 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.43339422 0.5666058 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.39910644 0.6008936 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00343275 0.99656725], shape=(2,), dtype=float32)\n","tf.Tensor([0.910281   0.08971898], shape=(2,), dtype=float32)\n","tf.Tensor([0.6124147  0.38758534], shape=(2,), dtype=float32)\n","tf.Tensor([0.4408185 0.5591815], shape=(2,), dtype=float32)\n","tf.Tensor([0.37712538 0.6228746 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.998844   0.00115589], shape=(2,), dtype=float32)\n","CV dominance:  [0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch   9 with loss = 13.76\n","tf.Tensor([0.72493035 0.2750697 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.14137606 0.8586239 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.18060447 0.8193955 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.08538185 0.9146182 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.26267138 0.73732865], shape=(2,), dtype=float32)\n","tf.Tensor([0.96456313 0.0354369 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.92746794 0.0725321 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.25875044 0.74124956], shape=(2,), dtype=float32)\n","tf.Tensor([0.77986515 0.22013485], shape=(2,), dtype=float32)\n","tf.Tensor([0.9882356  0.01176446], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  10 with loss = 14.26\n","tf.Tensor([0.23311141 0.7668886 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.07133696 0.9286631 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.05857187 0.9414282 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.2862779  0.71372205], shape=(2,), dtype=float32)\n","tf.Tensor([0.00130183 0.9986981 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.88973033 0.11026971], shape=(2,), dtype=float32)\n","tf.Tensor([0.83037287 0.16962712], shape=(2,), dtype=float32)\n","tf.Tensor([0.12212789 0.8778721 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.4945667 0.5054333], shape=(2,), dtype=float32)\n","tf.Tensor([0.9976077  0.00239231], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  11 with loss = 11.57\n","tf.Tensor([0.4814114  0.51858866], shape=(2,), dtype=float32)\n","tf.Tensor([0.1648552 0.8351448], shape=(2,), dtype=float32)\n","tf.Tensor([0.1722678 0.8277322], shape=(2,), dtype=float32)\n","tf.Tensor([0.24720171 0.7527983 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.04252413 0.9574759 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.78157634 0.21842363], shape=(2,), dtype=float32)\n","tf.Tensor([0.8853188  0.11468124], shape=(2,), dtype=float32)\n","tf.Tensor([0.12905999 0.87094   ], shape=(2,), dtype=float32)\n","tf.Tensor([0.36430457 0.63569546], shape=(2,), dtype=float32)\n","tf.Tensor([0.9972155  0.00278443], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  12 with loss = 11.52\n","tf.Tensor([0.81727815 0.18272193], shape=(2,), dtype=float32)\n","tf.Tensor([0.7670445  0.23295553], shape=(2,), dtype=float32)\n","tf.Tensor([0.05621939 0.9437806 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.23430395 0.765696  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00264667 0.9973533 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.69368243 0.3063176 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9429954  0.05700456], shape=(2,), dtype=float32)\n","tf.Tensor([0.9783036 0.0216964], shape=(2,), dtype=float32)\n","tf.Tensor([0.69564754 0.3043525 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9962449e-01 3.7550123e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  13 with loss = 20.44\n","tf.Tensor([0.30450583 0.6954942 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.13068111 0.86931884], shape=(2,), dtype=float32)\n","tf.Tensor([0.39104503 0.60895497], shape=(2,), dtype=float32)\n","tf.Tensor([0.30464464 0.69535536], shape=(2,), dtype=float32)\n","tf.Tensor([0.00454764 0.99545234], shape=(2,), dtype=float32)\n","tf.Tensor([0.93769914 0.06230085], shape=(2,), dtype=float32)\n","tf.Tensor([0.8713408 0.1286592], shape=(2,), dtype=float32)\n","tf.Tensor([0.09902699 0.90097296], shape=(2,), dtype=float32)\n","tf.Tensor([0.42084202 0.57915795], shape=(2,), dtype=float32)\n","tf.Tensor([0.99542785 0.00457208], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  14 with loss = 12.23\n","tf.Tensor([0.20922367 0.7907764 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.3274608 0.6725392], shape=(2,), dtype=float32)\n","tf.Tensor([0.13821751 0.8617825 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.20674172 0.7932583 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00766152 0.9923384 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.913571   0.08642898], shape=(2,), dtype=float32)\n","tf.Tensor([0.8674824  0.13251759], shape=(2,), dtype=float32)\n","tf.Tensor([0.1273525  0.87264746], shape=(2,), dtype=float32)\n","tf.Tensor([0.33105534 0.6689447 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9981755  0.00182454], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  15 with loss = 12.33\n","tf.Tensor([0.7772131  0.22278686], shape=(2,), dtype=float32)\n","tf.Tensor([0.11627463 0.88372535], shape=(2,), dtype=float32)\n","tf.Tensor([0.0751024  0.92489755], shape=(2,), dtype=float32)\n","tf.Tensor([0.14170761 0.85829234], shape=(2,), dtype=float32)\n","tf.Tensor([0.02579453 0.9742055 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.86707085 0.13292912], shape=(2,), dtype=float32)\n","tf.Tensor([0.9369339  0.06306614], shape=(2,), dtype=float32)\n","tf.Tensor([0.3420691 0.6579309], shape=(2,), dtype=float32)\n","tf.Tensor([0.3480612 0.6519388], shape=(2,), dtype=float32)\n","tf.Tensor([0.9954673  0.00453274], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  16 with loss = 12.91\n","tf.Tensor([0.33994505 0.6600549 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5618542  0.43814582], shape=(2,), dtype=float32)\n","tf.Tensor([0.02584084 0.9741591 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.08426657 0.9157334 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00423371 0.9957663 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84253806 0.15746196], shape=(2,), dtype=float32)\n","tf.Tensor([0.9789665  0.02103348], shape=(2,), dtype=float32)\n","tf.Tensor([0.7444398 0.2555602], shape=(2,), dtype=float32)\n","tf.Tensor([0.7343135 0.2656865], shape=(2,), dtype=float32)\n","tf.Tensor([9.9969327e-01 3.0671875e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  17 with loss = 17.85\n","tf.Tensor([0.37697878 0.6230212 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.63526857 0.3647314 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0783565  0.92164344], shape=(2,), dtype=float32)\n","tf.Tensor([0.26759875 0.73240125], shape=(2,), dtype=float32)\n","tf.Tensor([0.00405151 0.9959485 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8582086  0.14179145], shape=(2,), dtype=float32)\n","tf.Tensor([0.8157724  0.18422762], shape=(2,), dtype=float32)\n","tf.Tensor([0.36588144 0.6341185 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.14394678 0.8560532 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99569356 0.00430639], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  18 with loss = 11.58\n","tf.Tensor([0.3846292 0.6153708], shape=(2,), dtype=float32)\n","tf.Tensor([0.7373361 0.2626639], shape=(2,), dtype=float32)\n","tf.Tensor([0.35444826 0.64555174], shape=(2,), dtype=float32)\n","tf.Tensor([0.16886976 0.8311302 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01268805 0.98731196], shape=(2,), dtype=float32)\n","tf.Tensor([0.7030917  0.29690835], shape=(2,), dtype=float32)\n","tf.Tensor([0.77003646 0.22996348], shape=(2,), dtype=float32)\n","tf.Tensor([0.8027703  0.19722962], shape=(2,), dtype=float32)\n","tf.Tensor([0.6012801  0.39871985], shape=(2,), dtype=float32)\n","tf.Tensor([9.9922025e-01 7.7974721e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  19 with loss = 14.84\n","tf.Tensor([0.60175365 0.39824638], shape=(2,), dtype=float32)\n","tf.Tensor([0.28681692 0.71318305], shape=(2,), dtype=float32)\n","tf.Tensor([0.47480464 0.52519536], shape=(2,), dtype=float32)\n","tf.Tensor([0.38746214 0.61253786], shape=(2,), dtype=float32)\n","tf.Tensor([0.00277471 0.9972253 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7410711  0.25892892], shape=(2,), dtype=float32)\n","tf.Tensor([0.6688346 0.3311654], shape=(2,), dtype=float32)\n","tf.Tensor([0.16292426 0.8370757 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.6831161 0.3168839], shape=(2,), dtype=float32)\n","tf.Tensor([9.9916375e-01 8.3625875e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  20 with loss = 13.27\n","tf.Tensor([0.4944095 0.5055905], shape=(2,), dtype=float32)\n","tf.Tensor([0.21269596 0.78730404], shape=(2,), dtype=float32)\n","tf.Tensor([0.03118704 0.9688129 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.26739517 0.7326048 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00975575 0.99024427], shape=(2,), dtype=float32)\n","tf.Tensor([0.91265625 0.08734374], shape=(2,), dtype=float32)\n","tf.Tensor([0.86835444 0.13164556], shape=(2,), dtype=float32)\n","tf.Tensor([0.67897326 0.32102674], shape=(2,), dtype=float32)\n","tf.Tensor([0.16037385 0.8396262 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9922552  0.00774483], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  21 with loss = 11.91\n","tf.Tensor([0.8391256  0.16087447], shape=(2,), dtype=float32)\n","tf.Tensor([0.9113119 0.0886881], shape=(2,), dtype=float32)\n","tf.Tensor([0.20134646 0.79865354], shape=(2,), dtype=float32)\n","tf.Tensor([0.32596964 0.6740303 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00859869 0.99140126], shape=(2,), dtype=float32)\n","tf.Tensor([0.9321154  0.06788459], shape=(2,), dtype=float32)\n","tf.Tensor([0.8935616  0.10643841], shape=(2,), dtype=float32)\n","tf.Tensor([0.3788346  0.62116545], shape=(2,), dtype=float32)\n","tf.Tensor([0.25315937 0.7468406 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9931844  0.00681557], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  22 with loss = 15.56\n","tf.Tensor([0.6372453  0.36275473], shape=(2,), dtype=float32)\n","tf.Tensor([0.37375435 0.6262456 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.12924506 0.8707549 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.24805027 0.7519497 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03717716 0.9628228 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8897554  0.11024454], shape=(2,), dtype=float32)\n","tf.Tensor([0.8332567  0.16674325], shape=(2,), dtype=float32)\n","tf.Tensor([0.38680568 0.61319435], shape=(2,), dtype=float32)\n","tf.Tensor([0.28701007 0.71299   ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9978702  0.00212972], shape=(2,), dtype=float32)\n","CV dominance:  [0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  23 with loss = 12.92\n","tf.Tensor([0.7102654  0.28973463], shape=(2,), dtype=float32)\n","tf.Tensor([0.84797835 0.15202163], shape=(2,), dtype=float32)\n","tf.Tensor([0.25179434 0.74820566], shape=(2,), dtype=float32)\n","tf.Tensor([0.3877695  0.61223054], shape=(2,), dtype=float32)\n","tf.Tensor([0.03695063 0.9630494 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.92105836 0.07894168], shape=(2,), dtype=float32)\n","tf.Tensor([0.8555951  0.14440484], shape=(2,), dtype=float32)\n","tf.Tensor([0.5181582  0.48184177], shape=(2,), dtype=float32)\n","tf.Tensor([0.32426873 0.67573124], shape=(2,), dtype=float32)\n","tf.Tensor([0.9973138  0.00268614], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  24 with loss = 15.46\n","tf.Tensor([0.55278426 0.44721577], shape=(2,), dtype=float32)\n","tf.Tensor([0.25264987 0.74735016], shape=(2,), dtype=float32)\n","tf.Tensor([0.06569621 0.93430376], shape=(2,), dtype=float32)\n","tf.Tensor([0.08348623 0.9165138 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.24594617 0.7540539 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.91688246 0.08311752], shape=(2,), dtype=float32)\n","tf.Tensor([0.9812076  0.01879241], shape=(2,), dtype=float32)\n","tf.Tensor([0.99530643 0.00469354], shape=(2,), dtype=float32)\n","tf.Tensor([0.9977417  0.00225835], shape=(2,), dtype=float32)\n","tf.Tensor([9.9983656e-01 1.6346361e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","Starting epoch  25 with loss = 28.17\n","tf.Tensor([0.1576975  0.84230256], shape=(2,), dtype=float32)\n","tf.Tensor([0.0615677  0.93843234], shape=(2,), dtype=float32)\n","tf.Tensor([0.02581227 0.97418773], shape=(2,), dtype=float32)\n","tf.Tensor([0.19453101 0.805469  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03200606 0.9679939 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8302632  0.16973685], shape=(2,), dtype=float32)\n","tf.Tensor([0.89107275 0.10892722], shape=(2,), dtype=float32)\n","tf.Tensor([0.19663721 0.8033628 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7325822  0.26741776], shape=(2,), dtype=float32)\n","tf.Tensor([0.998811   0.00118898], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  26 with loss = 12.77\n","tf.Tensor([0.22441408 0.7755859 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5704652 0.4295348], shape=(2,), dtype=float32)\n","tf.Tensor([0.15059161 0.8494084 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.38880536 0.6111946 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01292017 0.9870798 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.829415   0.17058502], shape=(2,), dtype=float32)\n","tf.Tensor([0.83074516 0.16925487], shape=(2,), dtype=float32)\n","tf.Tensor([0.614096   0.38590395], shape=(2,), dtype=float32)\n","tf.Tensor([0.60213864 0.3978613 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.997291e-01 2.708634e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  27 with loss = 15.40\n","tf.Tensor([0.48497242 0.5150276 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00887087 0.99112916], shape=(2,), dtype=float32)\n","tf.Tensor([0.23293121 0.76706886], shape=(2,), dtype=float32)\n","tf.Tensor([0.11019733 0.88980263], shape=(2,), dtype=float32)\n","tf.Tensor([0.00124944 0.99875057], shape=(2,), dtype=float32)\n","tf.Tensor([0.9042197  0.09578031], shape=(2,), dtype=float32)\n","tf.Tensor([0.83216685 0.16783312], shape=(2,), dtype=float32)\n","tf.Tensor([0.1434697  0.85653025], shape=(2,), dtype=float32)\n","tf.Tensor([0.74422264 0.2557774 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9981501  0.00184997], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  28 with loss = 13.00\n","tf.Tensor([0.39070362 0.6092964 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01380111 0.9861989 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.06291146 0.9370886 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.2091549 0.7908451], shape=(2,), dtype=float32)\n","tf.Tensor([0.00238966 0.99761033], shape=(2,), dtype=float32)\n","tf.Tensor([0.8015928  0.19840714], shape=(2,), dtype=float32)\n","tf.Tensor([0.83141863 0.16858143], shape=(2,), dtype=float32)\n","tf.Tensor([0.16827993 0.83172005], shape=(2,), dtype=float32)\n","tf.Tensor([0.52411336 0.4758867 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99621373 0.0037862 ], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  29 with loss = 10.71\n","tf.Tensor([0.5771522 0.4228478], shape=(2,), dtype=float32)\n","tf.Tensor([0.8883004  0.11169965], shape=(2,), dtype=float32)\n","tf.Tensor([0.11278152 0.8872185 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.10309353 0.89690644], shape=(2,), dtype=float32)\n","tf.Tensor([0.18193623 0.8180638 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8715676  0.12843235], shape=(2,), dtype=float32)\n","tf.Tensor([0.9411106  0.05888942], shape=(2,), dtype=float32)\n","tf.Tensor([0.5487943 0.4512056], shape=(2,), dtype=float32)\n","tf.Tensor([0.33312654 0.66687346], shape=(2,), dtype=float32)\n","tf.Tensor([0.9974137  0.00258639], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  30 with loss = 15.52\n","tf.Tensor([0.12940936 0.8705906 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.19654436 0.80345565], shape=(2,), dtype=float32)\n","tf.Tensor([0.22084184 0.7791581 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.36794162 0.6320584 ], shape=(2,), dtype=float32)\n","tf.Tensor([7.283731e-04 9.992717e-01], shape=(2,), dtype=float32)\n","tf.Tensor([0.6760895  0.32391044], shape=(2,), dtype=float32)\n","tf.Tensor([0.81128    0.18871999], shape=(2,), dtype=float32)\n","tf.Tensor([0.4563604 0.5436396], shape=(2,), dtype=float32)\n","tf.Tensor([0.5250735  0.47492653], shape=(2,), dtype=float32)\n","tf.Tensor([9.9964380e-01 3.5615193e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n","\n","Starting epoch  31 with loss = 13.16\n","tf.Tensor([0.75367475 0.24632525], shape=(2,), dtype=float32)\n","tf.Tensor([0.5043143 0.4956857], shape=(2,), dtype=float32)\n","tf.Tensor([0.35346958 0.6465304 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.1668596 0.8331404], shape=(2,), dtype=float32)\n","tf.Tensor([0.16824937 0.8317507 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.50033116 0.49966884], shape=(2,), dtype=float32)\n","tf.Tensor([0.92358595 0.07641401], shape=(2,), dtype=float32)\n","tf.Tensor([0.15839978 0.8416002 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.670781   0.32921898], shape=(2,), dtype=float32)\n","tf.Tensor([9.9918586e-01 8.1413507e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  32 with loss = 14.57\n","tf.Tensor([0.2787795 0.7212205], shape=(2,), dtype=float32)\n","tf.Tensor([0.02037944 0.9796205 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.09885883 0.90114117], shape=(2,), dtype=float32)\n","tf.Tensor([0.05960694 0.9403931 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.13475904 0.86524093], shape=(2,), dtype=float32)\n","tf.Tensor([0.4757998 0.5242002], shape=(2,), dtype=float32)\n","tf.Tensor([0.85587263 0.14412738], shape=(2,), dtype=float32)\n","tf.Tensor([0.6080683 0.3919317], shape=(2,), dtype=float32)\n","tf.Tensor([0.9695246  0.03047536], shape=(2,), dtype=float32)\n","tf.Tensor([9.9982435e-01 1.7563198e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n","\n","Starting epoch  33 with loss = 16.32\n","tf.Tensor([0.31558585 0.68441415], shape=(2,), dtype=float32)\n","tf.Tensor([0.69459176 0.3054083 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15842888 0.8415711 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.29334038 0.7066596 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0016709 0.9983291], shape=(2,), dtype=float32)\n","tf.Tensor([0.92527777 0.07472219], shape=(2,), dtype=float32)\n","tf.Tensor([0.905829   0.09417094], shape=(2,), dtype=float32)\n","tf.Tensor([0.72419894 0.27580103], shape=(2,), dtype=float32)\n","tf.Tensor([0.35574073 0.64425933], shape=(2,), dtype=float32)\n","tf.Tensor([0.9975157  0.00248437], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  34 with loss = 14.77\n","tf.Tensor([0.26659605 0.733404  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0116087 0.9883913], shape=(2,), dtype=float32)\n","tf.Tensor([0.10610001 0.89390004], shape=(2,), dtype=float32)\n","tf.Tensor([0.3536862 0.6463138], shape=(2,), dtype=float32)\n","tf.Tensor([0.01052252 0.98947746], shape=(2,), dtype=float32)\n","tf.Tensor([0.9297696  0.07023037], shape=(2,), dtype=float32)\n","tf.Tensor([0.86383    0.13616998], shape=(2,), dtype=float32)\n","tf.Tensor([0.20731162 0.79268837], shape=(2,), dtype=float32)\n","tf.Tensor([0.47144315 0.5285569 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99894565 0.00105433], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  35 with loss = 13.26\n","tf.Tensor([0.28255376 0.7174462 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.42579   0.5742099], shape=(2,), dtype=float32)\n","tf.Tensor([0.43573952 0.5642605 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.25628662 0.7437134 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.02362893 0.97637105], shape=(2,), dtype=float32)\n","tf.Tensor([0.45716858 0.5428315 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.88039565 0.1196043 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.11650858 0.88349146], shape=(2,), dtype=float32)\n","tf.Tensor([0.4020505 0.5979495], shape=(2,), dtype=float32)\n","tf.Tensor([0.99805945 0.00194048], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n","\n","Starting epoch  36 with loss = 11.40\n","tf.Tensor([0.17306739 0.8269326 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.05034887 0.94965106], shape=(2,), dtype=float32)\n","tf.Tensor([0.06508697 0.93491304], shape=(2,), dtype=float32)\n","tf.Tensor([0.15176849 0.8482315 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0110051 0.9889949], shape=(2,), dtype=float32)\n","tf.Tensor([0.9375626  0.06243743], shape=(2,), dtype=float32)\n","tf.Tensor([0.9040333  0.09596667], shape=(2,), dtype=float32)\n","tf.Tensor([0.18910825 0.81089175], shape=(2,), dtype=float32)\n","tf.Tensor([0.59368783 0.4063122 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9912888e-01 8.7108294e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  37 with loss = 13.76\n","tf.Tensor([0.28770727 0.71229273], shape=(2,), dtype=float32)\n","tf.Tensor([0.72934246 0.2706576 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.17875357 0.82124645], shape=(2,), dtype=float32)\n","tf.Tensor([0.16841412 0.83158594], shape=(2,), dtype=float32)\n","tf.Tensor([0.07261315 0.9273868 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.60816693 0.3918331 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.97694916 0.02305085], shape=(2,), dtype=float32)\n","tf.Tensor([0.91249126 0.08750871], shape=(2,), dtype=float32)\n","tf.Tensor([0.7315188 0.2684812], shape=(2,), dtype=float32)\n","tf.Tensor([9.9974686e-01 2.5309241e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  38 with loss = 18.84\n","tf.Tensor([0.30613136 0.69386864], shape=(2,), dtype=float32)\n","tf.Tensor([0.00896819 0.9910319 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.19439138 0.80560863], shape=(2,), dtype=float32)\n","tf.Tensor([0.387835 0.612165], shape=(2,), dtype=float32)\n","tf.Tensor([0.03903349 0.96096647], shape=(2,), dtype=float32)\n","tf.Tensor([0.52313846 0.47686157], shape=(2,), dtype=float32)\n","tf.Tensor([0.900845 0.099155], shape=(2,), dtype=float32)\n","tf.Tensor([0.24102344 0.7589765 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5777579 0.4222421], shape=(2,), dtype=float32)\n","tf.Tensor([9.9960560e-01 3.9444587e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  39 with loss = 13.15\n","tf.Tensor([0.36439836 0.63560164], shape=(2,), dtype=float32)\n","tf.Tensor([0.3359202 0.6640798], shape=(2,), dtype=float32)\n","tf.Tensor([0.3803891 0.6196109], shape=(2,), dtype=float32)\n","tf.Tensor([0.17533544 0.82466453], shape=(2,), dtype=float32)\n","tf.Tensor([0.26090682 0.7390932 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.64572936 0.35427064], shape=(2,), dtype=float32)\n","tf.Tensor([0.7990745  0.20092554], shape=(2,), dtype=float32)\n","tf.Tensor([0.27251998 0.72748   ], shape=(2,), dtype=float32)\n","tf.Tensor([0.73575246 0.2642475 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9966347e-01 3.3649147e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  40 with loss = 14.12\n","tf.Tensor([0.5873267 0.4126733], shape=(2,), dtype=float32)\n","tf.Tensor([0.02350153 0.9764984 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.04780709 0.9521929 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.34387925 0.6561208 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.07274847 0.9272515 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5456579 0.4543421], shape=(2,), dtype=float32)\n","tf.Tensor([0.95994675 0.04005319], shape=(2,), dtype=float32)\n","tf.Tensor([0.5181296  0.48187038], shape=(2,), dtype=float32)\n","tf.Tensor([0.77717394 0.22282606], shape=(2,), dtype=float32)\n","tf.Tensor([0.99862766 0.0013724 ], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","Starting epoch  41 with loss = 14.28\n","tf.Tensor([0.8269241  0.17307593], shape=(2,), dtype=float32)\n","tf.Tensor([0.546552 0.453448], shape=(2,), dtype=float32)\n","tf.Tensor([0.06957781 0.9304221 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.08539167 0.9146083 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01929271 0.9807072 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.93492895 0.06507101], shape=(2,), dtype=float32)\n","tf.Tensor([0.93669933 0.06330069], shape=(2,), dtype=float32)\n","tf.Tensor([0.49310935 0.50689065], shape=(2,), dtype=float32)\n","tf.Tensor([0.59507126 0.4049287 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9987668  0.00123326], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  42 with loss = 16.50\n","tf.Tensor([0.28413346 0.71586657], shape=(2,), dtype=float32)\n","tf.Tensor([0.7820265  0.21797347], shape=(2,), dtype=float32)\n","tf.Tensor([0.18070534 0.81929463], shape=(2,), dtype=float32)\n","tf.Tensor([0.15610853 0.8438915 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.06522496 0.93477505], shape=(2,), dtype=float32)\n","tf.Tensor([0.5438117  0.45618835], shape=(2,), dtype=float32)\n","tf.Tensor([0.97156674 0.02843334], shape=(2,), dtype=float32)\n","tf.Tensor([0.8882036  0.11179634], shape=(2,), dtype=float32)\n","tf.Tensor([0.5154182  0.48458186], shape=(2,), dtype=float32)\n","tf.Tensor([9.997130e-01 2.869613e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  43 with loss = 17.71\n","tf.Tensor([0.34139305 0.65860695], shape=(2,), dtype=float32)\n","tf.Tensor([0.35266766 0.6473324 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.05956446 0.9404355 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.25527915 0.7447209 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.06843141 0.9315686 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9604191  0.03958092], shape=(2,), dtype=float32)\n","tf.Tensor([0.8232068  0.17679319], shape=(2,), dtype=float32)\n","tf.Tensor([0.32198668 0.6780133 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5267537  0.47324625], shape=(2,), dtype=float32)\n","tf.Tensor([0.9990007  0.00099926], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  44 with loss = 14.29\n","tf.Tensor([0.64583266 0.35416737], shape=(2,), dtype=float32)\n","tf.Tensor([0.5674579  0.43254212], shape=(2,), dtype=float32)\n","tf.Tensor([0.14507896 0.854921  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.3193629  0.68063706], shape=(2,), dtype=float32)\n","tf.Tensor([0.00499708 0.9950029 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9754033  0.02459665], shape=(2,), dtype=float32)\n","tf.Tensor([0.7421114  0.25788864], shape=(2,), dtype=float32)\n","tf.Tensor([0.08415822 0.9158418 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.28197953 0.71802044], shape=(2,), dtype=float32)\n","tf.Tensor([0.99420667 0.00579337], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  45 with loss = 13.05\n","tf.Tensor([0.63416135 0.36583868], shape=(2,), dtype=float32)\n","tf.Tensor([0.8280823  0.17191769], shape=(2,), dtype=float32)\n","tf.Tensor([0.41778207 0.58221793], shape=(2,), dtype=float32)\n","tf.Tensor([0.13522638 0.86477363], shape=(2,), dtype=float32)\n","tf.Tensor([0.62846637 0.37153363], shape=(2,), dtype=float32)\n","tf.Tensor([0.82889616 0.17110386], shape=(2,), dtype=float32)\n","tf.Tensor([0.98997575 0.01002424], shape=(2,), dtype=float32)\n","tf.Tensor([0.9466757  0.05332433], shape=(2,), dtype=float32)\n","tf.Tensor([0.9538143  0.04618571], shape=(2,), dtype=float32)\n","tf.Tensor([9.9979132e-01 2.0874671e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n","\n","Starting epoch  46 with loss = 25.29\n","tf.Tensor([0.63014984 0.36985013], shape=(2,), dtype=float32)\n","tf.Tensor([0.02131651 0.9786835 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.04107972 0.9589203 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.14523529 0.8547647 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00408458 0.99591535], shape=(2,), dtype=float32)\n","tf.Tensor([0.8978777  0.10212228], shape=(2,), dtype=float32)\n","tf.Tensor([0.8439825  0.15601751], shape=(2,), dtype=float32)\n","tf.Tensor([0.15690471 0.8430953 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.69162196 0.30837804], shape=(2,), dtype=float32)\n","tf.Tensor([9.9944073e-01 5.5931316e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  47 with loss = 14.19\n","tf.Tensor([0.8145297  0.18547027], shape=(2,), dtype=float32)\n","tf.Tensor([0.62362146 0.3763785 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5103556  0.48964438], shape=(2,), dtype=float32)\n","tf.Tensor([0.1502716 0.8497284], shape=(2,), dtype=float32)\n","tf.Tensor([0.08834198 0.911658  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.29566386 0.7043361 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7757172  0.22428279], shape=(2,), dtype=float32)\n","tf.Tensor([0.07111303 0.92888695], shape=(2,), dtype=float32)\n","tf.Tensor([0.64911574 0.35088423], shape=(2,), dtype=float32)\n","tf.Tensor([9.9936265e-01 6.3739682e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n","\n","Starting epoch  48 with loss = 13.96\n","tf.Tensor([0.2696454  0.73035467], shape=(2,), dtype=float32)\n","tf.Tensor([0.44200587 0.5579941 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.16885011 0.8311499 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15475307 0.845247  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.22344424 0.7765557 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.73665047 0.26334953], shape=(2,), dtype=float32)\n","tf.Tensor([0.9843196  0.01568044], shape=(2,), dtype=float32)\n","tf.Tensor([0.9612405  0.03875955], shape=(2,), dtype=float32)\n","tf.Tensor([0.61876816 0.3812318 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9961996e-01 3.7995662e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  49 with loss = 19.08\n","tf.Tensor([0.22423162 0.77576834], shape=(2,), dtype=float32)\n","tf.Tensor([0.4193336  0.58066636], shape=(2,), dtype=float32)\n","tf.Tensor([0.2603782 0.7396218], shape=(2,), dtype=float32)\n","tf.Tensor([0.12909698 0.8709031 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.07085542 0.92914456], shape=(2,), dtype=float32)\n","tf.Tensor([0.72736764 0.27263236], shape=(2,), dtype=float32)\n","tf.Tensor([0.8179799  0.18202008], shape=(2,), dtype=float32)\n","tf.Tensor([0.36408255 0.6359175 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.40062428 0.59937567], shape=(2,), dtype=float32)\n","tf.Tensor([0.9980313  0.00196868], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  50 with loss = 11.51\n","tf.Tensor([0.30492836 0.6950717 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.4706925 0.5293075], shape=(2,), dtype=float32)\n","tf.Tensor([0.05749695 0.94250304], shape=(2,), dtype=float32)\n","tf.Tensor([0.16677687 0.8332231 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00667281 0.99332714], shape=(2,), dtype=float32)\n","tf.Tensor([0.9443249  0.05567512], shape=(2,), dtype=float32)\n","tf.Tensor([0.85168576 0.14831428], shape=(2,), dtype=float32)\n","tf.Tensor([0.60087454 0.39912543], shape=(2,), dtype=float32)\n","tf.Tensor([0.30359083 0.69640917], shape=(2,), dtype=float32)\n","tf.Tensor([0.9926791  0.00732094], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  51 with loss = 12.24\n","tf.Tensor([0.21222156 0.78777844], shape=(2,), dtype=float32)\n","tf.Tensor([0.31087244 0.68912756], shape=(2,), dtype=float32)\n","tf.Tensor([0.23373653 0.7662635 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.16152401 0.838476  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.029419   0.97058094], shape=(2,), dtype=float32)\n","tf.Tensor([0.793256   0.20674406], shape=(2,), dtype=float32)\n","tf.Tensor([0.9500785  0.04992151], shape=(2,), dtype=float32)\n","tf.Tensor([0.8463714  0.15362856], shape=(2,), dtype=float32)\n","tf.Tensor([0.75986546 0.24013446], shape=(2,), dtype=float32)\n","tf.Tensor([9.990343e-01 9.656933e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  52 with loss = 15.90\n","tf.Tensor([0.31837404 0.6816259 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.64913 0.35087], shape=(2,), dtype=float32)\n","tf.Tensor([0.07928866 0.9207113 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.31884548 0.68115455], shape=(2,), dtype=float32)\n","tf.Tensor([0.00670604 0.993294  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.97298855 0.02701144], shape=(2,), dtype=float32)\n","tf.Tensor([0.9887058  0.01129418], shape=(2,), dtype=float32)\n","tf.Tensor([0.95115924 0.04884076], shape=(2,), dtype=float32)\n","tf.Tensor([0.8256284  0.17437163], shape=(2,), dtype=float32)\n","tf.Tensor([9.9924767e-01 7.5238536e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  53 with loss = 21.96\n","tf.Tensor([0.33752507 0.6624749 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.35215214 0.64784783], shape=(2,), dtype=float32)\n","tf.Tensor([0.09426273 0.9057373 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.17986253 0.8201375 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0067494  0.99325055], shape=(2,), dtype=float32)\n","tf.Tensor([0.58398664 0.4160134 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8909792  0.10902084], shape=(2,), dtype=float32)\n","tf.Tensor([0.4052916 0.5947084], shape=(2,), dtype=float32)\n","tf.Tensor([0.7867538  0.21324617], shape=(2,), dtype=float32)\n","tf.Tensor([0.9978575  0.00214247], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  54 with loss = 12.45\n","tf.Tensor([0.3871989  0.61280113], shape=(2,), dtype=float32)\n","tf.Tensor([0.8579904  0.14200959], shape=(2,), dtype=float32)\n","tf.Tensor([0.1112687  0.88873136], shape=(2,), dtype=float32)\n","tf.Tensor([0.11963858 0.8803614 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03450841 0.9654916 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.6990316  0.30096838], shape=(2,), dtype=float32)\n","tf.Tensor([0.9794698  0.02053025], shape=(2,), dtype=float32)\n","tf.Tensor([0.9638661 0.0361338], shape=(2,), dtype=float32)\n","tf.Tensor([0.9471655  0.05283451], shape=(2,), dtype=float32)\n","tf.Tensor([9.9969614e-01 3.0383651e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  55 with loss = 22.17\n","tf.Tensor([0.07248265 0.92751735], shape=(2,), dtype=float32)\n","tf.Tensor([0.02565161 0.9743484 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.10728813 0.8927119 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.14875229 0.8512477 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00818421 0.99181575], shape=(2,), dtype=float32)\n","tf.Tensor([0.49665755 0.50334245], shape=(2,), dtype=float32)\n","tf.Tensor([0.8152174  0.18478267], shape=(2,), dtype=float32)\n","tf.Tensor([0.35494515 0.6450548 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.72525483 0.27474517], shape=(2,), dtype=float32)\n","tf.Tensor([9.9913639e-01 8.6365885e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n","\n","Starting epoch  56 with loss = 11.54\n","tf.Tensor([0.5429617  0.45703822], shape=(2,), dtype=float32)\n","tf.Tensor([0.01408733 0.9859126 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15601066 0.8439893 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.60554487 0.3944552 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00158971 0.9984102 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.95993555 0.04006443], shape=(2,), dtype=float32)\n","tf.Tensor([0.61661226 0.38338768], shape=(2,), dtype=float32)\n","tf.Tensor([0.05994489 0.9400551 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5802072 0.4197928], shape=(2,), dtype=float32)\n","tf.Tensor([9.9919266e-01 8.0731662e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  57 with loss = 14.13\n","tf.Tensor([0.63599205 0.36400795], shape=(2,), dtype=float32)\n","tf.Tensor([0.8693662  0.13063376], shape=(2,), dtype=float32)\n","tf.Tensor([0.12950361 0.8704964 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.20097984 0.7990201 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00355292 0.99644715], shape=(2,), dtype=float32)\n","tf.Tensor([0.9624326  0.03756735], shape=(2,), dtype=float32)\n","tf.Tensor([0.8276415  0.17235859], shape=(2,), dtype=float32)\n","tf.Tensor([0.17666213 0.82333785], shape=(2,), dtype=float32)\n","tf.Tensor([0.6579204  0.34207952], shape=(2,), dtype=float32)\n","tf.Tensor([0.9960788  0.00392119], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  58 with loss = 15.26\n","tf.Tensor([0.6558834  0.34411663], shape=(2,), dtype=float32)\n","tf.Tensor([0.97161794 0.02838206], shape=(2,), dtype=float32)\n","tf.Tensor([0.41719338 0.58280665], shape=(2,), dtype=float32)\n","tf.Tensor([0.13585146 0.86414856], shape=(2,), dtype=float32)\n","tf.Tensor([0.3758405 0.6241595], shape=(2,), dtype=float32)\n","tf.Tensor([0.82453805 0.17546193], shape=(2,), dtype=float32)\n","tf.Tensor([0.97303444 0.02696547], shape=(2,), dtype=float32)\n","tf.Tensor([0.954388   0.04561196], shape=(2,), dtype=float32)\n","tf.Tensor([0.94645566 0.05354428], shape=(2,), dtype=float32)\n","tf.Tensor([9.9988675e-01 1.1326073e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  59 with loss = 26.24\n","tf.Tensor([0.32903007 0.6709699 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.07967333 0.92032665], shape=(2,), dtype=float32)\n","tf.Tensor([0.06502476 0.9349752 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.12172611 0.87827384], shape=(2,), dtype=float32)\n","tf.Tensor([0.00877804 0.9912219 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9281327  0.07186729], shape=(2,), dtype=float32)\n","tf.Tensor([0.89120823 0.10879179], shape=(2,), dtype=float32)\n","tf.Tensor([0.26677433 0.7332257 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.54640394 0.45359606], shape=(2,), dtype=float32)\n","tf.Tensor([0.98739606 0.01260392], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  60 with loss = 11.01\n","tf.Tensor([0.62453556 0.37546447], shape=(2,), dtype=float32)\n","tf.Tensor([0.6578041  0.34219596], shape=(2,), dtype=float32)\n","tf.Tensor([0.13696888 0.8630311 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.3320645 0.6679355], shape=(2,), dtype=float32)\n","tf.Tensor([0.01254912 0.98745096], shape=(2,), dtype=float32)\n","tf.Tensor([0.8497587  0.15024127], shape=(2,), dtype=float32)\n","tf.Tensor([0.9268479  0.07315218], shape=(2,), dtype=float32)\n","tf.Tensor([0.560686   0.43931404], shape=(2,), dtype=float32)\n","tf.Tensor([0.44368768 0.5563123 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99889046 0.00110959], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  61 with loss = 15.34\n","tf.Tensor([0.9143916  0.08560846], shape=(2,), dtype=float32)\n","tf.Tensor([0.9592379  0.04076216], shape=(2,), dtype=float32)\n","tf.Tensor([0.20055664 0.79944336], shape=(2,), dtype=float32)\n","tf.Tensor([0.17444147 0.8255585 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.13765633 0.8623437 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5797411  0.42025888], shape=(2,), dtype=float32)\n","tf.Tensor([0.9851307  0.01486921], shape=(2,), dtype=float32)\n","tf.Tensor([0.98094004 0.01905989], shape=(2,), dtype=float32)\n","tf.Tensor([0.958797   0.04120303], shape=(2,), dtype=float32)\n","tf.Tensor([9.9997485e-01 2.5181387e-05], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  62 with loss = 29.04\n","tf.Tensor([0.19267902 0.80732095], shape=(2,), dtype=float32)\n","tf.Tensor([0.01842842 0.9815716 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03066531 0.9693347 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.28892678 0.7110732 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.02167914 0.97832084], shape=(2,), dtype=float32)\n","tf.Tensor([0.8660947 0.1339053], shape=(2,), dtype=float32)\n","tf.Tensor([0.7690733  0.23092668], shape=(2,), dtype=float32)\n","tf.Tensor([0.21652102 0.7834789 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.49344507 0.50655496], shape=(2,), dtype=float32)\n","tf.Tensor([0.98556846 0.01443153], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  63 with loss =  9.27\n","tf.Tensor([0.2361132 0.7638868], shape=(2,), dtype=float32)\n","tf.Tensor([0.49357584 0.5064242 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.11547503 0.88452494], shape=(2,), dtype=float32)\n","tf.Tensor([0.27370247 0.72629756], shape=(2,), dtype=float32)\n","tf.Tensor([0.00154103 0.998459  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8642378  0.13576223], shape=(2,), dtype=float32)\n","tf.Tensor([0.88589853 0.11410142], shape=(2,), dtype=float32)\n","tf.Tensor([0.6227926  0.37720743], shape=(2,), dtype=float32)\n","tf.Tensor([0.58615047 0.41384956], shape=(2,), dtype=float32)\n","tf.Tensor([0.99841535 0.00158467], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  64 with loss = 13.87\n","tf.Tensor([0.23095451 0.7690455 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00760632 0.99239373], shape=(2,), dtype=float32)\n","tf.Tensor([0.12317548 0.8768245 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.21983102 0.780169  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01517039 0.9848296 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84727407 0.1527259 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84680986 0.15319009], shape=(2,), dtype=float32)\n","tf.Tensor([0.15581316 0.84418684], shape=(2,), dtype=float32)\n","tf.Tensor([0.6235548  0.37644523], shape=(2,), dtype=float32)\n","tf.Tensor([0.99771285 0.00228721], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  65 with loss = 11.65\n","tf.Tensor([0.5925269 0.4074731], shape=(2,), dtype=float32)\n","tf.Tensor([0.10561036 0.8943897 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.10991126 0.8900888 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.36490956 0.6350905 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01084219 0.9891578 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9733508  0.02664914], shape=(2,), dtype=float32)\n","tf.Tensor([0.75752825 0.24247175], shape=(2,), dtype=float32)\n","tf.Tensor([0.06185775 0.93814224], shape=(2,), dtype=float32)\n","tf.Tensor([0.35819882 0.6418011 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9888039 0.0111961], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  66 with loss = 11.63\n","tf.Tensor([0.28114653 0.71885353], shape=(2,), dtype=float32)\n","tf.Tensor([0.2660666  0.73393345], shape=(2,), dtype=float32)\n","tf.Tensor([0.79726326 0.20273668], shape=(2,), dtype=float32)\n","tf.Tensor([0.23628077 0.7637192 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15905927 0.8409407 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84275043 0.15724961], shape=(2,), dtype=float32)\n","tf.Tensor([0.9574877  0.04251229], shape=(2,), dtype=float32)\n","tf.Tensor([0.1388146 0.8611854], shape=(2,), dtype=float32)\n","tf.Tensor([0.52571607 0.474284  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9958389  0.00416112], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  67 with loss = 14.06\n","tf.Tensor([0.14942282 0.8505772 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.02070249 0.9792976 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0467406  0.95325935], shape=(2,), dtype=float32)\n","tf.Tensor([0.19518794 0.8048121 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01031797 0.989682  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.76108056 0.23891942], shape=(2,), dtype=float32)\n","tf.Tensor([0.75265926 0.24734074], shape=(2,), dtype=float32)\n","tf.Tensor([0.34670827 0.6532917 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.64386874 0.35613126], shape=(2,), dtype=float32)\n","tf.Tensor([0.9978728 0.0021272], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  68 with loss = 10.90\n","tf.Tensor([0.3659541  0.63404584], shape=(2,), dtype=float32)\n","tf.Tensor([0.6346165  0.36538357], shape=(2,), dtype=float32)\n","tf.Tensor([0.14357077 0.8564292 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.21176507 0.7882349 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01421044 0.9857896 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8907317  0.10926838], shape=(2,), dtype=float32)\n","tf.Tensor([0.9366916  0.06330843], shape=(2,), dtype=float32)\n","tf.Tensor([0.9061207  0.09387934], shape=(2,), dtype=float32)\n","tf.Tensor([0.6602279 0.3397721], shape=(2,), dtype=float32)\n","tf.Tensor([9.9963439e-01 3.6554673e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  69 with loss = 18.20\n","tf.Tensor([0.0977247 0.9022753], shape=(2,), dtype=float32)\n","tf.Tensor([0.16065909 0.8393409 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.17399973 0.82600033], shape=(2,), dtype=float32)\n","tf.Tensor([0.18197988 0.8180201 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00472337 0.9952767 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.60360867 0.39639133], shape=(2,), dtype=float32)\n","tf.Tensor([0.8188035  0.18119656], shape=(2,), dtype=float32)\n","tf.Tensor([0.42446455 0.5755354 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.2604528  0.73954713], shape=(2,), dtype=float32)\n","tf.Tensor([0.99308723 0.00691274], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  70 with loss =  9.14\n","tf.Tensor([0.8581984  0.14180164], shape=(2,), dtype=float32)\n","tf.Tensor([0.8699291  0.13007095], shape=(2,), dtype=float32)\n","tf.Tensor([0.08439468 0.91560537], shape=(2,), dtype=float32)\n","tf.Tensor([0.11230928 0.8876907 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00148251 0.99851745], shape=(2,), dtype=float32)\n","tf.Tensor([0.9365854  0.06341451], shape=(2,), dtype=float32)\n","tf.Tensor([0.9609078  0.03909221], shape=(2,), dtype=float32)\n","tf.Tensor([0.67842805 0.321572  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.23290455 0.7670955 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9971575e-01 2.8419940e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  71 with loss = 19.77\n","tf.Tensor([0.36933005 0.63066995], shape=(2,), dtype=float32)\n","tf.Tensor([0.96775293 0.03224705], shape=(2,), dtype=float32)\n","tf.Tensor([0.20213467 0.79786533], shape=(2,), dtype=float32)\n","tf.Tensor([0.07472546 0.9252745 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01086213 0.9891378 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.87094975 0.12905027], shape=(2,), dtype=float32)\n","tf.Tensor([0.97198707 0.02801295], shape=(2,), dtype=float32)\n","tf.Tensor([0.9356366 0.0643634], shape=(2,), dtype=float32)\n","tf.Tensor([0.8228642  0.17713583], shape=(2,), dtype=float32)\n","tf.Tensor([9.9939573e-01 6.0422975e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  72 with loss = 21.72\n","tf.Tensor([0.5762902  0.42370984], shape=(2,), dtype=float32)\n","tf.Tensor([0.50203717 0.4979629 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.11807984 0.8819202 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.39516917 0.6048308 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00804921 0.99195075], shape=(2,), dtype=float32)\n","tf.Tensor([0.90397066 0.09602941], shape=(2,), dtype=float32)\n","tf.Tensor([0.75691813 0.24308185], shape=(2,), dtype=float32)\n","tf.Tensor([0.5429829 0.4570171], shape=(2,), dtype=float32)\n","tf.Tensor([0.3483204  0.65167964], shape=(2,), dtype=float32)\n","tf.Tensor([0.9986199 0.0013801], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  73 with loss = 13.75\n","tf.Tensor([0.32775557 0.6722444 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00986841 0.9901316 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0518142  0.94818574], shape=(2,), dtype=float32)\n","tf.Tensor([0.24996652 0.7500335 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01750159 0.9824984 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.92140687 0.07859316], shape=(2,), dtype=float32)\n","tf.Tensor([0.90439725 0.09560275], shape=(2,), dtype=float32)\n","tf.Tensor([0.11708582 0.8829141 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.6861147  0.31388527], shape=(2,), dtype=float32)\n","tf.Tensor([0.99812573 0.00187423], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  74 with loss = 13.22\n","tf.Tensor([0.29746044 0.7025396 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03657125 0.9634288 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.05593833 0.94406164], shape=(2,), dtype=float32)\n","tf.Tensor([0.22618939 0.7738106 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.08850328 0.9114967 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.829528  0.1704721], shape=(2,), dtype=float32)\n","tf.Tensor([0.72793776 0.2720622 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.24907242 0.75092757], shape=(2,), dtype=float32)\n","tf.Tensor([0.6639016  0.33609843], shape=(2,), dtype=float32)\n","tf.Tensor([0.99793386 0.00206619], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  75 with loss = 11.43\n","tf.Tensor([0.36878642 0.63121355], shape=(2,), dtype=float32)\n","tf.Tensor([0.5430197  0.45698026], shape=(2,), dtype=float32)\n","tf.Tensor([0.5419482  0.45805177], shape=(2,), dtype=float32)\n","tf.Tensor([0.24774359 0.7522564 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.4294339  0.57056606], shape=(2,), dtype=float32)\n","tf.Tensor([0.59008986 0.40991008], shape=(2,), dtype=float32)\n","tf.Tensor([0.9698168  0.03018316], shape=(2,), dtype=float32)\n","tf.Tensor([0.7707896  0.22921036], shape=(2,), dtype=float32)\n","tf.Tensor([0.38769445 0.6123055 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9929154e-01 7.0842233e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  76 with loss = 16.48\n","tf.Tensor([0.20904283 0.7909572 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03418979 0.9658102 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.04201124 0.9579887 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.10990027 0.89009976], shape=(2,), dtype=float32)\n","tf.Tensor([0.11333572 0.8866642 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.47068045 0.5293196 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8811167  0.11888333], shape=(2,), dtype=float32)\n","tf.Tensor([0.15521386 0.8447861 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7051728 0.2948272], shape=(2,), dtype=float32)\n","tf.Tensor([0.9973476  0.00265237], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n","\n","Starting epoch  77 with loss = 10.64\n","tf.Tensor([0.24971291 0.75028706], shape=(2,), dtype=float32)\n","tf.Tensor([0.10250659 0.8974934 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.31067544 0.6893245 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.18962601 0.810374  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01505879 0.9849412 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.8440957  0.15590431], shape=(2,), dtype=float32)\n","tf.Tensor([0.82999575 0.17000423], shape=(2,), dtype=float32)\n","tf.Tensor([0.07914764 0.92085236], shape=(2,), dtype=float32)\n","tf.Tensor([0.60292953 0.39707047], shape=(2,), dtype=float32)\n","tf.Tensor([0.99392277 0.00607718], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  78 with loss = 10.73\n","tf.Tensor([0.30735582 0.6926442 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.29671052 0.70328945], shape=(2,), dtype=float32)\n","tf.Tensor([0.14061035 0.85938966], shape=(2,), dtype=float32)\n","tf.Tensor([0.14885464 0.8511454 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.0568914 0.9431086], shape=(2,), dtype=float32)\n","tf.Tensor([0.62686926 0.37313068], shape=(2,), dtype=float32)\n","tf.Tensor([0.97134084 0.02865923], shape=(2,), dtype=float32)\n","tf.Tensor([0.48004076 0.5199593 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.63383293 0.36616704], shape=(2,), dtype=float32)\n","tf.Tensor([0.9953513  0.00464869], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n","\n","Starting epoch  79 with loss = 12.66\n","tf.Tensor([0.33820012 0.6617999 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.20118679 0.79881316], shape=(2,), dtype=float32)\n","tf.Tensor([0.32338646 0.6766135 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.133063 0.866937], shape=(2,), dtype=float32)\n","tf.Tensor([0.3730276  0.62697244], shape=(2,), dtype=float32)\n","tf.Tensor([0.23983498 0.76016504], shape=(2,), dtype=float32)\n","tf.Tensor([0.91319567 0.08680431], shape=(2,), dtype=float32)\n","tf.Tensor([0.307255 0.692745], shape=(2,), dtype=float32)\n","tf.Tensor([0.82760334 0.17239669], shape=(2,), dtype=float32)\n","tf.Tensor([9.996377e-01 3.622076e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n","\n","Starting epoch  80 with loss = 14.40\n","tf.Tensor([0.63542503 0.36457497], shape=(2,), dtype=float32)\n","tf.Tensor([0.6348366  0.36516342], shape=(2,), dtype=float32)\n","tf.Tensor([0.06164973 0.9383502 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.3073693 0.6926307], shape=(2,), dtype=float32)\n","tf.Tensor([0.00401182 0.9959882 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.96679395 0.03320603], shape=(2,), dtype=float32)\n","tf.Tensor([0.9571001  0.04289989], shape=(2,), dtype=float32)\n","tf.Tensor([0.86258775 0.13741228], shape=(2,), dtype=float32)\n","tf.Tensor([0.582831   0.41716892], shape=(2,), dtype=float32)\n","tf.Tensor([0.9985085  0.00149144], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  81 with loss = 18.37\n","tf.Tensor([0.37506706 0.62493294], shape=(2,), dtype=float32)\n","tf.Tensor([0.35068247 0.6493175 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.16918498 0.830815  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.3706502  0.62934977], shape=(2,), dtype=float32)\n","tf.Tensor([0.00260118 0.99739885], shape=(2,), dtype=float32)\n","tf.Tensor([0.9235096 0.0764904], shape=(2,), dtype=float32)\n","tf.Tensor([0.7192083 0.2807917], shape=(2,), dtype=float32)\n","tf.Tensor([0.4553803 0.5446197], shape=(2,), dtype=float32)\n","tf.Tensor([0.80994517 0.1900548 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.997104e-01 2.896385e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n","\n","Starting epoch  82 with loss = 15.81\n","tf.Tensor([0.5257746 0.4742254], shape=(2,), dtype=float32)\n","tf.Tensor([0.03989834 0.96010166], shape=(2,), dtype=float32)\n","tf.Tensor([0.10328757 0.8967125 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15162067 0.8483794 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.09238683 0.9076132 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.928483   0.07151706], shape=(2,), dtype=float32)\n","tf.Tensor([0.7519045  0.24809553], shape=(2,), dtype=float32)\n","tf.Tensor([0.17566894 0.82433105], shape=(2,), dtype=float32)\n","tf.Tensor([0.6935805  0.30641952], shape=(2,), dtype=float32)\n","tf.Tensor([9.992091e-01 7.909710e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  83 with loss = 13.71\n","tf.Tensor([0.49106655 0.5089335 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.7669937  0.23300628], shape=(2,), dtype=float32)\n","tf.Tensor([0.1414753 0.8585247], shape=(2,), dtype=float32)\n","tf.Tensor([0.1601843 0.8398157], shape=(2,), dtype=float32)\n","tf.Tensor([0.04299299 0.95700705], shape=(2,), dtype=float32)\n","tf.Tensor([0.8461055  0.15389448], shape=(2,), dtype=float32)\n","tf.Tensor([0.844869   0.15513097], shape=(2,), dtype=float32)\n","tf.Tensor([0.13605121 0.8639488 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.60620546 0.39379454], shape=(2,), dtype=float32)\n","tf.Tensor([9.9935263e-01 6.4730685e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  84 with loss = 14.66\n","tf.Tensor([0.19555952 0.8044405 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.57563215 0.42436782], shape=(2,), dtype=float32)\n","tf.Tensor([0.45872685 0.5412732 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15779522 0.84220475], shape=(2,), dtype=float32)\n","tf.Tensor([0.19965474 0.80034524], shape=(2,), dtype=float32)\n","tf.Tensor([0.71667916 0.28332084], shape=(2,), dtype=float32)\n","tf.Tensor([0.95243895 0.04756099], shape=(2,), dtype=float32)\n","tf.Tensor([0.36461976 0.63538027], shape=(2,), dtype=float32)\n","tf.Tensor([0.31202072 0.6879792 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9981065  0.00189345], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  85 with loss = 13.49\n","tf.Tensor([0.45400113 0.5459989 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.26081225 0.7391878 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.18703574 0.8129643 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.14279857 0.8572014 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.1204904 0.8795096], shape=(2,), dtype=float32)\n","tf.Tensor([0.6429516  0.35704842], shape=(2,), dtype=float32)\n","tf.Tensor([0.8432145 0.1567855], shape=(2,), dtype=float32)\n","tf.Tensor([0.20657726 0.79342276], shape=(2,), dtype=float32)\n","tf.Tensor([0.4986233 0.5013767], shape=(2,), dtype=float32)\n","tf.Tensor([9.9943560e-01 5.6442345e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  86 with loss = 12.68\n","tf.Tensor([0.42416406 0.57583594], shape=(2,), dtype=float32)\n","tf.Tensor([0.8140474  0.18595259], shape=(2,), dtype=float32)\n","tf.Tensor([0.46077338 0.53922665], shape=(2,), dtype=float32)\n","tf.Tensor([0.2318314  0.76816857], shape=(2,), dtype=float32)\n","tf.Tensor([0.0643359 0.9356641], shape=(2,), dtype=float32)\n","tf.Tensor([0.74604714 0.25395283], shape=(2,), dtype=float32)\n","tf.Tensor([0.8566113  0.14338861], shape=(2,), dtype=float32)\n","tf.Tensor([0.39540365 0.6045964 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.23507646 0.7649236 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9984856  0.00151437], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  87 with loss = 13.76\n","tf.Tensor([0.46486068 0.5351394 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.2807485 0.7192515], shape=(2,), dtype=float32)\n","tf.Tensor([0.07472131 0.92527866], shape=(2,), dtype=float32)\n","tf.Tensor([0.2108739 0.7891261], shape=(2,), dtype=float32)\n","tf.Tensor([0.2737064  0.72629356], shape=(2,), dtype=float32)\n","tf.Tensor([0.8306838  0.16931623], shape=(2,), dtype=float32)\n","tf.Tensor([0.9388465  0.06115342], shape=(2,), dtype=float32)\n","tf.Tensor([0.6699427  0.33005732], shape=(2,), dtype=float32)\n","tf.Tensor([0.42744812 0.57255185], shape=(2,), dtype=float32)\n","tf.Tensor([9.9961168e-01 3.8833922e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  88 with loss = 15.68\n","tf.Tensor([0.6218515  0.37814844], shape=(2,), dtype=float32)\n","tf.Tensor([0.73379695 0.26620308], shape=(2,), dtype=float32)\n","tf.Tensor([0.32507387 0.67492616], shape=(2,), dtype=float32)\n","tf.Tensor([0.27702668 0.7229733 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.01652584 0.9834742 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.721698   0.27830204], shape=(2,), dtype=float32)\n","tf.Tensor([0.8443774 0.1556226], shape=(2,), dtype=float32)\n","tf.Tensor([0.54934645 0.45065352], shape=(2,), dtype=float32)\n","tf.Tensor([0.26708534 0.7329147 ], shape=(2,), dtype=float32)\n","tf.Tensor([9.9933165e-01 6.6835573e-04], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  89 with loss = 14.59\n","tf.Tensor([0.7000365  0.29996347], shape=(2,), dtype=float32)\n","tf.Tensor([0.76445764 0.23554234], shape=(2,), dtype=float32)\n","tf.Tensor([0.08535995 0.91464   ], shape=(2,), dtype=float32)\n","tf.Tensor([0.15662168 0.84337837], shape=(2,), dtype=float32)\n","tf.Tensor([0.18487473 0.8151252 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.9592292  0.04077079], shape=(2,), dtype=float32)\n","tf.Tensor([0.96957517 0.03042488], shape=(2,), dtype=float32)\n","tf.Tensor([0.8487934  0.15120663], shape=(2,), dtype=float32)\n","tf.Tensor([0.86130846 0.13869151], shape=(2,), dtype=float32)\n","tf.Tensor([0.99864286 0.0013571 ], shape=(2,), dtype=float32)\n","CV dominance:  [1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","Starting epoch  90 with loss = 20.27\n","tf.Tensor([0.457205 0.542795], shape=(2,), dtype=float32)\n","tf.Tensor([0.9330661  0.06693382], shape=(2,), dtype=float32)\n","tf.Tensor([0.59407216 0.40592787], shape=(2,), dtype=float32)\n","tf.Tensor([0.23876797 0.761232  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.34614658 0.6538534 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.5489357  0.45106426], shape=(2,), dtype=float32)\n","tf.Tensor([0.8369155  0.16308454], shape=(2,), dtype=float32)\n","tf.Tensor([0.3045251  0.69547486], shape=(2,), dtype=float32)\n","tf.Tensor([0.33195314 0.66804683], shape=(2,), dtype=float32)\n","tf.Tensor([0.9973456 0.0026544], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  91 with loss = 14.22\n","tf.Tensor([0.52783376 0.47216624], shape=(2,), dtype=float32)\n","tf.Tensor([0.22907858 0.7709214 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.05742132 0.9425787 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.22097015 0.77902985], shape=(2,), dtype=float32)\n","tf.Tensor([0.0015897 0.9984102], shape=(2,), dtype=float32)\n","tf.Tensor([0.97899306 0.02100693], shape=(2,), dtype=float32)\n","tf.Tensor([0.8504823  0.14951773], shape=(2,), dtype=float32)\n","tf.Tensor([0.1576033 0.8423967], shape=(2,), dtype=float32)\n","tf.Tensor([0.48831034 0.5116896 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99317026 0.00682975], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  92 with loss = 12.91\n","tf.Tensor([0.2644597 0.7355403], shape=(2,), dtype=float32)\n","tf.Tensor([0.15862858 0.8413715 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.03934798 0.960652  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.12675792 0.8732421 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.00601834 0.99398166], shape=(2,), dtype=float32)\n","tf.Tensor([0.6296317  0.37036833], shape=(2,), dtype=float32)\n","tf.Tensor([0.9243749  0.07562508], shape=(2,), dtype=float32)\n","tf.Tensor([0.3638307 0.6361693], shape=(2,), dtype=float32)\n","tf.Tensor([0.53817505 0.46182495], shape=(2,), dtype=float32)\n","tf.Tensor([0.99782616 0.00217381], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  93 with loss = 11.59\n","tf.Tensor([0.14056562 0.85943437], shape=(2,), dtype=float32)\n","tf.Tensor([0.01564903 0.98435104], shape=(2,), dtype=float32)\n","tf.Tensor([0.16371801 0.836282  ], shape=(2,), dtype=float32)\n","tf.Tensor([0.21062383 0.78937614], shape=(2,), dtype=float32)\n","tf.Tensor([0.00129594 0.9987041 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.68663794 0.31336212], shape=(2,), dtype=float32)\n","tf.Tensor([0.6739362  0.32606378], shape=(2,), dtype=float32)\n","tf.Tensor([0.07802839 0.92197156], shape=(2,), dtype=float32)\n","tf.Tensor([0.43152937 0.56847066], shape=(2,), dtype=float32)\n","tf.Tensor([0.9981389  0.00186105], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","\n","Starting epoch  94 with loss =  9.80\n","tf.Tensor([0.34768066 0.6523194 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.42890394 0.5710961 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.06124251 0.9387575 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.09471896 0.90528107], shape=(2,), dtype=float32)\n","tf.Tensor([0.01003936 0.9899607 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.73721284 0.26278713], shape=(2,), dtype=float32)\n","tf.Tensor([0.9057004  0.09429962], shape=(2,), dtype=float32)\n","tf.Tensor([0.6756141  0.32438588], shape=(2,), dtype=float32)\n","tf.Tensor([0.9614825  0.03851744], shape=(2,), dtype=float32)\n","tf.Tensor([0.99590284 0.00409713], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","Starting epoch  95 with loss = 14.74\n","tf.Tensor([0.541931 0.458069], shape=(2,), dtype=float32)\n","tf.Tensor([0.7560886 0.2439114], shape=(2,), dtype=float32)\n","tf.Tensor([0.36376444 0.63623554], shape=(2,), dtype=float32)\n","tf.Tensor([0.0845845 0.9154155], shape=(2,), dtype=float32)\n","tf.Tensor([0.27956942 0.7204306 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84299713 0.15700291], shape=(2,), dtype=float32)\n","tf.Tensor([0.95904857 0.04095148], shape=(2,), dtype=float32)\n","tf.Tensor([0.3604105  0.63958955], shape=(2,), dtype=float32)\n","tf.Tensor([0.25097346 0.74902654], shape=(2,), dtype=float32)\n","tf.Tensor([0.99806315 0.00193685], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n","\n","Starting epoch  96 with loss = 15.09\n","tf.Tensor([0.80468065 0.19531938], shape=(2,), dtype=float32)\n","tf.Tensor([0.6600616  0.33993837], shape=(2,), dtype=float32)\n","tf.Tensor([0.15503584 0.84496415], shape=(2,), dtype=float32)\n","tf.Tensor([0.18429035 0.81570965], shape=(2,), dtype=float32)\n","tf.Tensor([0.00761721 0.9923828 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.84037143 0.15962857], shape=(2,), dtype=float32)\n","tf.Tensor([0.7441319  0.25586808], shape=(2,), dtype=float32)\n","tf.Tensor([0.50505203 0.49494797], shape=(2,), dtype=float32)\n","tf.Tensor([0.23275001 0.76725   ], shape=(2,), dtype=float32)\n","tf.Tensor([0.998899   0.00110101], shape=(2,), dtype=float32)\n","CV dominance:  [0, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n","\n","Starting epoch  97 with loss = 14.07\n","tf.Tensor([0.4545838 0.5454162], shape=(2,), dtype=float32)\n","tf.Tensor([0.6875162  0.31248376], shape=(2,), dtype=float32)\n","tf.Tensor([0.27884936 0.72115064], shape=(2,), dtype=float32)\n","tf.Tensor([0.26043373 0.73956627], shape=(2,), dtype=float32)\n","tf.Tensor([0.08118031 0.9188197 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.77876246 0.22123757], shape=(2,), dtype=float32)\n","tf.Tensor([0.93507195 0.06492803], shape=(2,), dtype=float32)\n","tf.Tensor([0.9153159  0.08468401], shape=(2,), dtype=float32)\n","tf.Tensor([0.65060186 0.34939814], shape=(2,), dtype=float32)\n","tf.Tensor([9.9974471e-01 2.5526326e-04], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n","\n","Starting epoch  98 with loss = 18.52\n","tf.Tensor([0.5620372  0.43796274], shape=(2,), dtype=float32)\n","tf.Tensor([0.09448278 0.90551716], shape=(2,), dtype=float32)\n","tf.Tensor([0.6123397  0.38766026], shape=(2,), dtype=float32)\n","tf.Tensor([0.16304608 0.8369539 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.46677157 0.53322846], shape=(2,), dtype=float32)\n","tf.Tensor([0.5110908  0.48890916], shape=(2,), dtype=float32)\n","tf.Tensor([0.9553155  0.04468453], shape=(2,), dtype=float32)\n","tf.Tensor([0.44767338 0.5523266 ], shape=(2,), dtype=float32)\n","tf.Tensor([0.99889034 0.00110964], shape=(2,), dtype=float32)\n","tf.Tensor([9.999882e-01 1.175705e-05], shape=(2,), dtype=float32)\n","CV dominance:  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n","\n","Starting epoch  99 with loss = 25.25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xIp1puviFNxR","colab_type":"text"},"source":["CVD plot"]},{"cell_type":"code","metadata":{"id":"JbauWaxnCstM","colab_type":"code","outputId":"d3b7c182-fedc-4a61-e135-934bf3942091","executionInfo":{"status":"ok","timestamp":1578759524852,"user_tz":-60,"elapsed":579,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["#plt.plot(range(10), np.mean(np.asarray(all_dominances), 0))\n","#print(np.std(np.asarray(all_dominances),0).shape)\n","plt.errorbar(range(10), np.mean(np.asarray(all_dominances), 0), ss.sem(np.asarray(all_dominances), 0), marker='s', mfc='red', ms=4)\n","plt.ylim(bottom=0, top=1)\n","plt.ylabel('CVD (%)')\n","plt.xlabel('Frame')\n","\n","last_value = np.mean(np.asarray(all_dominances), 0)[-1]\n","plt.arrow(9, last_value, -0.5, 0.3)\n","plt.annotate(str(last_value), xy=(8, last_value+0.35))"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(8, 0.85, '0.5')"]},"metadata":{"tags":[]},"execution_count":26},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXgV5fn/8fedjSzsELYkbLKDrGGT\nYnEHVEBR0dpqtdYuaPXburUqRaj+8NtalWoXq9S2+hUVVKIiKLghopiwSVgjBJKwG0jYQrb798c5\nwRASsnDmzEnmfl1XruucmcmZOyfJ+cwzzzzPiKpijDHGu8LcLsAYY4y7LAiMMcbjLAiMMcbjLAiM\nMcbjLAiMMcbjLAiMMcbjHAsCEZkjIvtEZH0V60VEZotIhoisE5HBTtVijDGmak62CF4Exp5h/Tig\nu//rduBvDtZijDGmCo4Fgap+CuSeYZOJwH/U5wuguYi0d6oeY4wxlYtwcd8JQFa559n+Zbsrbigi\nt+NrNRAXFzekV69eQSnQGGMairS0tAOqGl/ZOjeDoMZU9TngOYDk5GRNTU11uSJjjKlfRGRHVevc\nvGooB0gq9zzRv8wYY0wQuRkEKcBN/quHRgB5qnraaSFjjDHOcuzUkIi8AowBWotINvB7IBJAVf8O\nLATGAxnAMeAWp2oxxhhTNceCQFVvqGa9AlOd2r8xxpiasZHFxhjjcRYExhjjcRYExhjjcRYExhjj\ncRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYE\nxhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhjjcRYExhhTA4sWLaJnz55069aN\nWbNmnbb+xRdfJD4+noEDBzJw4ECef/55F6qsmwi3CzDGmFBXUlLC1KlT+eCDD0hMTGTo0KFMmDCB\nPn36nLLdlClTeOaZZ1yqsu6sRWCMMdVYuXIl3bp1o2vXrkRFRXH99dezYMECt8sKGAsCY4ypRk5O\nDklJSSefJyYmkpOTc9p28+fPp3///lxzzTVkZWUFs8SzYkFgjDEBcOWVV5KZmcm6deu45JJLuPnm\nm90uqcYsCIwxphoJCQmnHOFnZ2eTkJBwyjatWrWiUaNGANx2222kpaUFtcazYUFgjDHVGDp0KFu3\nbmX79u0UFhYyd+5cJkyYcMo2u3fvPvk4JSWF3r17B7vMOrOrhowxphoRERE888wzXHbZZZSUlHDr\nrbfSt29fpk2bRnJyMhMmTGD27NmkpKQQERFBy5YtefHFF90uu8ZEVd2uoVaSk5M1NTXV7TKMMaZe\nEZE0VU2ubJ2dGjLGGI+zIDDGGI+zIDDGGI+zIDDGGI+zIDDGGI+zIDDGGI9zNAhEZKyIbBaRDBF5\noJL1HUXkIxFZLSLrRGS8k/UYY4w5nWNBICLhwLPAOKAPcIOI9Kmw2UPAa6o6CLge+KtT9RhjjKmc\nky2CYUCGqm5T1UJgLjCxwjYKNPU/bgbscrAeY4xxhYjw73//2+0yquRkECQA5edhzfYvK2868EMR\nyQYWAndW9kIicruIpIpI6v79+52o1RhjHHXPPfe4XUKV3O4svgF4UVUTgfHAf0XktJpU9TlVTVbV\n5Pj4+KAXaYwxZ2PixIkcOHDA7TKq5GQQ5ABJ5Z4n+peV9xPgNQBVXQFEA60drMkYY4JuxowZABQU\nFLhcSeWcDIKvgO4i0kVEovB1BqdU2GYncBGAiPTGFwR27scY06D0798fIGRvaO9YEKhqMXAHsBjY\niO/qoHQRmSEiZRN5/wb4qYisBV4Bfqz1bTpUY4ypoQcffNDtEirl6P0IVHUhvk7g8sumlXu8ARjl\nZA3GGBMKbr31VubMmeN2GZVyu7PYGGM84eGHHwYgLy/P5UpOZ0FgjDFB0LlzZwCeeuopdwuphAWB\nMcYE0fTp090u4TQWBMYYEyT33nuv2yVUyoLAGGOCpCwIdu/e7XIlp7IgMMaYICmbGWHWrFkuV3Iq\nCwJjjAmi8PBwZs+e7XYZp7AgMMaYIHr00UfdLuE0FgTGGBNEU6dOBWDr1q0uV/IdCwJjjAmixo0b\nA/DII4+4XMl3LAiMMSbI2rRpw8svv+x2GSdZEBhjTJCFWj+BBYExxgTZTTfdBMBXX33lciU+FgTG\nGBNkUVFRAEybNq2aLYPDgsAYY1zQu3dvFi1a5HYZgAWBMca4oqyfIBTuxWVBYIwxLpg4cSIAH3zw\ngcuVWBAYY4wrwsJ8H78PPfSQy5VYEBhjjGu+973vhcSVQxYExhjjkj/84Q8AlJSUuFqHBYExxrjk\n/PPPB+D11193tQ4LAmOMcYmIAPDggw+6WocFgTHGuGjixIls27bN1RosCIwxxkVls5AWFBS4VoMF\ngTHGuGjAgAEAvPDCC67VYEFgjDFnMOUfK5jyjxWO78fN8QQWBMYY47Jbb72VQ4cOubZ/CwJjjHFZ\nWWsgLy/Plf1bEBhjjMu6dOkCwOzZs13ZvwWBMcaECLfuT2BBYIwxIeCee+5xbd8WBMYYEwLuu+8+\nAHbv3h30fVsQGGNMCIiPjwdg1qxZQd+3hMLdcWojOTlZU1NT3S7DGOMBo6YvJKfgu8/IhGhh+fTx\nju0vPDyc0tJSR+5aJiJpqppc2TpHWwQiMlZENotIhog8UMU214nIBhFJF5H/c7IeY4ypjZwCJfPx\nK05+lQ8FJ5TdvjLYHAsCEQkHngXGAX2AG0SkT4VtugO/BUapal/gbqfqMcaYUHfHHXcAsHXr1qDu\n18kWwTAgQ1W3qWohMBeYWGGbnwLPqupBAFXd52A9xhhz1tbnODfoq3HjxgDMmDHDsX1UxskgSACy\nyj3P9i8rrwfQQ0SWi8gXIjK2shcSkdtFJFVEUvfv3+9QucYY8x1VJba0iM73v3PyK6akiKv+upy/\nf/INJaXOnCaKj4/npZdecuS1q+L2VUMRQHdgDHAD8E8RaV5xI1V9TlWTVTW5rGfdGGOctD4nn2Nh\nkXRuFcvwLi3JnHU5Kx4ZzyV92jLrvU3c+PwX7Dp0POD7daOfwMkgyAGSyj1P9C8rLxtIUdUiVd0O\nbMEXDMYY46r5q7KJigijVVzUyWXNY6N49geD+eM1/fk6O4+xT33K22t3BXS/N998MwDBvDrSySD4\nCuguIl1EJAq4HkipsM1b+FoDiEhrfKeK3L1VjzHG8wqLS1mwJodL+rQlIvzUj0kR4drkJBbeNZpz\n2jTmzldW8+tX13C4oCgg+46K8gVPMKebqDYIRGSkiDwrIutEZL+I7BSRhSIyVUSaVfV9qloM3AEs\nBjYCr6lquojMEJEJ/s0WA9+KyAbgI+BeVf327H8sY4ypu4837+PgsSKuGZxY5TadWsXx+s9GcvfF\n3Vmwdhfjnl5GamZuQPbfq1cv3nvvvYC8Vk2cMQhE5D3gNnwf2GOB9vguBX0IiAYWlPtQP42qLlTV\nHqp6jqo+6l82TVVT/I9VVX+tqn1U9VxVnRuYH8sYY+pu/qpsWjduxOjurc+4XUR4GHdf3IPXfjaS\nMBGu+8cKnnh/M0UlpWe1/7J+gmAN+K2uRfAjVf2Jqqao6i5VLVbVI6q6SlWfUNUxwOdBqNMYY4Li\n4NFCPty0j0kDO5x2WqgqQzq1YOFdo7l6cCJ/+TCDa/6+gu0Hjta5hkmTJgGwZMmSOr9GbZzxp1TV\nAxWXichFInKliERWtY0xxtRXKWt3UVSiTB5S9WmhyjRuFMGfrh3AX28cTOaBo1w+exlzV+6s01F9\nWJjvozlYt6+sVWexiDwBjAIGAAscqcgYY1w0f1U2fdo3pXf7pnX6/vHntmfR3aMZmNScB974mp/9\nN43co4W1fp1Ro0axcuXKOtVQW9X1ETxR4br+jsBM4FH/Y2POSrBuDG5MTWzde5h12XmntAZe/dlI\nXv3ZyFq9TvtmMbz0k+E8OL43H2/ez9inPuXTLbUbDDtz5kwASkpKavV9dVFdi+ANYK6I/Mo/d9B/\n8F3dswL4p9PFGWNMMM1flUN4mDBhQIezfq2wMOGn53flramjaBYTyU1zVjLj7Q0UFNXsg33MmDEA\nzJs376xrqU51fQTLVXUskIvvyiFR1TGqOkJVn3a8ugCyI89T2fthquLVv42SUuXN1dmM6RFPfJNG\nAXvdPh2a8vad3+PH53VmzvLtTHp2OZv25Ff7fSICwIMPPgg4+3up7tRQhIhcDuwDJgEDRCRFRAY4\nUo0xxrhkecYB9uafqHUncU1ER4YzfUJf/nXLUA4cKWTCM8t54bPtlFYzX9GECRP45ptvAl5PRdWd\nGnoLGAh8H98soTOBnwN3ioidGjINhlePgs135q/KpllMJBf1buPYPi7o2YbFd4/m/O7xzHxnAzf/\nayV78wuq3L5sFtITJ044VhNUHwSd/APBHgHOBfCPJ7gN370GjDGm3jtcUMTi9D1cOaA9jSLCHd1X\nq8aN+OdNQ3j0qn58lZnL2Kc+ZdH6PZVuO2CA7+TLCy+84GhN1QXBcyKyAvgE+HP5Faq6xrGqjDEm\niN77eg8FRaVcfYYpJQJJRLhxeCfe/dVoElvE8vOX0rh/3jqOniiudPuyfgKnVNdZ/BdVHen/Cu4E\n2cYYEyTzVmXTtXUcg5JOmwXfUefEN2b+L87jl2PO4bW0LC6fvYw1WYdO2eaWW27h0KFDVbxCYFTX\nWfyQiLQ4w/oLReSKwJdljDHBkZV7jJXbc5k8JPHklTrBFBURxn1jezH3pyN8I5r/9jmzl26l2D9f\n0cMPPww4O54gopr1XwPviEgBsArYj2+yue74OpGXAI85Vp1p0EZNX3jyZuCdH3iXhGhh+fTxLldl\nvGb+qmxE4KpBFW+gGFzDu7Zi4V2jmbZgPX/+YAufbtnPk1MG0qVLFwCys7Pp1KmTI/s+YxCo6gJ8\nM4x2xze1RHsgH3gJuF1VA397HlNvlZYqh08Uk3+8iLzjReQXFJF/vIj848Unn+cdLzq5PqdAyXz8\nuwZl5/vfYV5aNoktYkhqGUu7ptGEhwX/CM14h6ryxqoczjunFR2ax7hdDs1iInn6+kFc2KsND725\nnnFPL+ORCX0ByMzMdCwIJFjTnAZKcnKy1vbOPeWPPAHPH3me6f0oKCrxfXif/NAu9yF+7NTlJx/7\n1x0+UcyZ/pxEoGl0JE1jImgWE8n6nPzTgqC8yHChQ/MYklrEktQyhsQWsSS1jCXJHxSt4qIC1pQv\nu3S0tlMJNDRe+1/5KjOXa/++gieuHeDI+IGzkZV7jN+8tpaVmbnEFBdwPCL65Lq6/F5EJE1Vkytb\nV92poQahsiNPL6vs/Rj66BLyjhdRWHzmedSjI8NoFhNJ0+hImsVE0rZpND3aNqFptO/DvWnZl399\n05gI3+PYSBpHRRBW7gi/8wPvnvb6H90zhqzcY2QdPEZW7nGyDh4jO/cYi9PzT5u4KzYq3Nd68AdE\nWUuiLDiaREee5TvlPV77X5mflk1sVDhj+7Vzu5TTJLWM5ZXbR/D3T77hj4s3O/p78UQQmOpd3LuN\n/2jd9+X7sP/uw71ZTCRNoiMCeo11QrSc8gedEC10aR1Hl9ZxlW5/5EQx2WUB4Q+L7IO+x19uz+VI\nhUvvmsVEktTyu6BIahFDoj8oElvEEB3p+1msrwL25BXw4ueZbpcRVAVFJby7bjfj+rUnrlFofhSG\nhwlTL+jGHxdvdnQ/ofnTG8dUNaT9/13dP8iVwPLp42t1SqZxowh6tWtKr3anTw+sqhw6VnRKS8IX\nFsfZvOcwSzfuo7DCXaPaNGlEUstYzx0Fl7dhVz7PL9tGytpdlNaz08Rna3H6Hg6fKGbyEHc7iUNB\ntUEgIhcAdwI9/Ys2As+o6scO1hVQFY88m0rlgza84NXULKKKC087Eq/vRIQWcVG0iIuif+Lp14KX\nlir7Dp/wtSgqtCoqk3esiGaxDfPUkqryyZb9PL9sO59lHCA2KpwfjujEraO6cMNfPj7lb6NNZMMN\nhzdW5ZDQPIYRXVq5XUq1Kms9B9IZg8A/4dwzwAx800wIMBiYIyJ3qOrCgFbjkPJHngM7Nucfn2xj\n1c6DDO5Y5RCJBung0UIeX7SJgd3bgSoi4pnO0bAwoV2zaNo1iya5c8tT1lXWVzH0sSWM7duOKUOT\nGNm11Sl9G/XVieISFqzexfOfbWPL3iO0bdqI+8b25MZhnU6GXtn/SmmpsvPgMTq1ikP9fysNyd78\nApZt3c8vx3SrF7/b2raea6u6FsG9wCRVXVtu2RoRSQX+AtSLICjvVxd2Z8HqXUxbsJ4FU7/nqcsT\n//j+Zg4XFDNjYl9+vyDd7XJCRsWjrbZRymVDknhrdQ4pa3eR2CKGa4ckcU1yIgkOXmLo1D/6waOF\nvPzlDv69Ygf7D5+gV7smPHHtAK4c0IGoiMrHlIaFCb8c043fp6Sz4ptvOa/bmW/iXt+8tTqHUoWr\nB9tpIag+CNpVCAEAVHWdiLR1qCZHxTWK4MHLe3PnK6v5v5U7+dEIZ67LDTXrsg/xysqd/Pi8zpWe\nY/eyqo62fje+N4vT9/BaahZPLtnCU0u3MLp7PNclJ3JJn7aOT052tjIPHGXO8u28nprN8aISzu8R\nz5+v68L3urWu0RH+lKFJ/O3jb3hqyVZGntOqwbQKVJX5q7IZ3LE5XeMbu11OSKguCI7WcV1Iu6J/\ne15ZuZM/Ld7M5ee2p2VclNslOaq0VJm2IJ1WcY34n0t6uF1OvREdGc7EgQlMHJhAVu4xXk/N4vW0\nbO74v9W0iI1k0qAEpgxNCqlgVVXSdhzkn8u28f6GvUSGhTFxYAduG92Vnu2a1Oq1oiPD+eUF5zBt\nQTqff/MtoxpIq2B9Tj5b9h7h0av6uV1KyKguCM4RkZRKlgvQ1YF6gkJEeGRCX8Y9vYz/XbSJWZOD\nf8VMML2elsWarEM8ce0Amtq19XWS1DKWX1/ak7su7sFnGQd47assXvpiB/9ansmAxGZcm5zEhIEd\nXHt/i0tKWZy+l38u28aarEM0i4nkl2PO4eaRnWnTNLr6F6jClKFJ/PWjb3hqyRbOayCtgvmrsomK\nCOOKc8/+dpQNRXVBMPEM6/4UyEKCrXvbJtwyqjPPf7ad64d1ZGCQZx0MlkPHCnl80WaGdm5h50MD\nIDxM+H6PeL7fI57co4W8tTqH11KzeOit9fzh3Q2M79ee64YmMbxLy6B8aB49UcxrqVnMWb6drNzj\ndGoVy4yJfblmSCKxUWd/dXijiHCmXnAODy9IZ3nGt3yve/1uFRQWl5KydheX9G7bYK8Kq4vq/lKG\nAXNVNSsYxQTbXRf3YMEaX8fxm78c1SA7jp94fwuHjhXyyIThIXk0V5+vWmoZF8Wt3+vCLaM6sy47\nj1dTs3h7zS7eWJ1Dp1axXJecxOTBibRrVvcj8qrszfcNAHv5ix3kFxQzpFMLHhzfh0v6tA343/F1\nQ5P468e+VsGobvW7VfDx5n3kHi20sQMVVBcEHYDPRSQTeAV4XVX3O15VkDT2dxzfNXcNr36VxQ+G\nd3S7pIBan5PHy1/u4KaRnenTIXTOYzc0IsKApOYMSGrOw5f34b31u3n1qyz+uHgzT7y/me/3iGfK\n0CQu7NW2yqt0amrj7nz+uWwbb6/dRUmpMrZfO24b3dXRS6EbRYTzywu68fBb6/ks4wCju8c7ti+n\nzV+VTevGjTi/Hv8MTqh20jnxxf/5wPX4bmC/Fl8ovKGqhx2vsIK6TDp3JqrK9c99wea9h/noN2No\n0UA6jktLlcl//5ys3GMs/c0YmsVYM/hMnLh0M/PAUV5Py2JeWjZ780/QKi6Kqwf7Opi7tTm947aq\nGlSVT7ce4Pll21i21TcA7LrkJG4d1YWOrWIDVu+ZnCgu4YI/fkz75jHM+/nIetkqOHi0kGGPLeHm\nkZ156Io+bpcTdGeadK7awxP1+URVfwEkAk8CdwN7A1umO0SEGRP7cbigmP91eD6PYJq3KpvVOw9x\n/9heFgIu6dw6jnsv68Xy+y9kzo+TSe7cgn8tz+TiP3/KVX9dztyVO0+bH6m8E8UlvJaaxdinlnHz\nnJVs3nOY+8b2ZMUDFzF9Qt+ghQB81ypI23GQzzIOBG2/gfT2ul2+G7+E2CyjoaDG01CLyLn4WgVT\ngAPAK6r6tIO1VSrQLYIyM9/ZwJzl21kwdVSlUxTUJ3nHirjwiY/p1CqWeT8/r16MnPSKA0dO8Oaq\nHF5NzSJj3xFio8K5/Nz2fLIui31F3/2eWoSVEhEXc3IA2E9Hdz3jALBgKGsVtGsWzfxfnFfvWgUT\nn/mMwhLlvbtGu12KK+o8DbX/hjQ34PvwLwHmApeq6raAV+myuy/uTsraXTy8IJ03f1G/Pzz//MFm\nDh4r5N+3DqvXP0dD1LpxI356flduG92FVTsP8XpqFm+v3cXRIjlt4rvz2zet1QAwpzWKCGfqhd14\n8M31LNt6gPN71J/z7Bn7DrM2O4+HLu/tdikhqbrDi0VAFDBFVfur6mMNMQQAmkRH8rvxvVibdYjX\nUuvvRVLpu/L47xc7+OGITvRLaOZ2OaYKIsKQTi2YNbk/Kx+8uNJt/nPrMEZ3jw+JEChz7ZAkOjSL\n5sklW6hPN7Wal5ZDeJgwcaBdLVSZ6oJgLLBIVdeXXygio0TkHOfKcsekgQkM69ySxxdt4tCxwuq/\nIcSoKr9fkE6L2Ch+c0nP6r/BhIRQnQu/MlERYUy9sBurdx7i0631o6+gpFR5c3U2Y3rEE9+kkdvl\nhKTqguBJIK+S5fnAU4Evx10iwiMT+5JfUMyf3q9/HcdvrMohdcdBXwexDZapV8omviv7CuWpwa8d\nkkRC8xie/KB+tAo+/+YAe/NPWCfxGVQXBG1V9euKC/3LOjtSkct6t2/KTSM78fKXO/k6u7IMDE15\nx4v4f+9tZGBSc66xP/h6Z/n08Qzv0pLhXVqSOevykL5DWlREGFMv6MaarEN8siX0hxXNT8umaXQE\nF/Vu43YpIau6IDjT5TPVzscrImNFZLOIZIjIA2fYbrKIqIhU2qMdbP9zSQ9axTXi4QXrq7yjV6h5\n8oMtfHu0kJkT+1kHsXHcNUN8U3I/uWRrSLcKDhcUsSh9D1cO6BDys8W6qbogSBWRn1ZcKCK3AWln\n+kYRCQeeBcYBfYAbROS0URwi0gS4C/iypkU7rWl0JL8d14s1WYeYl5btdjnV2rg7n/+syOQHwzpy\nbqJ1EBvnRUWEcceF3VibdYiPQ7hV8N7XeygoKrXTQtWoLgjuBm4RkY9F5An/1yfAT/B9eJ/JMCBD\nVbepaiG+S08rm8RuJvA4UFDL2h119eAEkju1YNaiTeQdK3K7nCqpKtMWrKdZTCT3XmYdxCZ4Jg9O\nJLFFDE+FcKtg3qpsuraOY1ADnVQyUM4YBKq6V1XPw3ebykz/1yOqOlJV91Tz2glA+esws/3LThKR\nwUCSqp5+r8BTt7tdRFJFJHX//uAcfZSNOD50rJAnPgjdjuO31uTwVaavg7h5bMOYHsPUD1ERYdxx\ngb9VsDn0WgVZucdYuT2XyUMSQ+oS3FBUo2GKqvqRqv7F//VhIHYsImHAn4Hf1GD/z6lqsqomx8cH\nbxBLnw5N+dGITrz0xQ7Sd4Vex/HhgiIeW7iJAUnNuS45ye1yjAdNHlLWKgi9K4jeWJWDCEwaZGMH\nquPkePUcoPynU6J/WZkmQD/gY//spiOAlFDpMC7z60t70iI2imkL0kOu4/ipJVs5cOQEMyf2tQ5i\n44rI8DDuvLAba7Pz+GjzPrfLOUlVeWN1NiO7tnL0PtMNhZNB8BXQXUS6iEgUvnmKTt7tTFXzVLW1\nqnZW1c7AF8AEVQ38REJnoVlMJPeP60XajoPMXxU6Hceb9xzmxc8zuX5ox3o/N5Kp364enEhSy9Dq\nK0jdcZAd3x5j8mDrJK4Jx4JAVYuBO4DFwEbgNVVNF5EZIjLBqf064ZrBiQzu2JxZ720i77j7Hcdl\nHcRNoiO4zzqIG4xXfzayXt6oJzI8jDsv6M667Dw+3BQarYL5adnERoUztl87t0upFxydylBVF6pq\nD1U9R1Uf9S+bpqqn3QdZVceEWmugTFiYr+P44LFCnvxgi9vlkLJ2F19uz+Xey3o2mPsnmPrtqsEJ\ndGwZGxKtgoKiEt5dt5tx/drXq+k73OTenLb1TL+EZtw4vBP/WZHJhl35rtVxuKCIR9/dyLkJzbh+\naMO6o5qpvyLDfeMKvs7JY+lGd1sF72/Yy+ETxXY7ylqwIKiFey7tSfPYKH6fst61o57ZS7ey/8gJ\nZk7q1yDvsWzqr6sG+VsFS929gmh+WjYJzWMY0aWVazXUNxYEtdAsNpL7x/bkq8yDvLk6p/pvCLCt\new/zr+WZTElOYqANkDEhpuwKovU5+SxxqVWwN7+AZVv3c9WgBLuSrhYsCGrp2iG+D+HHFm4ivyB4\nHce+DuJ04hpFcN/YXkHbrzG1cdWgBDq1inVtXMFbq3MoVd/MAKbmLAhqyddx3Jdvj54IasfxO+t2\ns2Lbt9xzWU9aWgexCVER4b7Rxum7gt8qUFXmr8pmcMfmdI1vHNR913cWBHXQP7E5NwzryH9W7GDT\nHuc7jo+eKObRdzfSL6EpPxhmHcQmtLnVKkjflc+WvUdsgrk6sCCoo3sv7UnT6AimvZXu+B/77A+3\nsie/gEcmWAexCX0R4WHceWF30nfl88GGvUHb77y0bKIiwrji3A5B22dDYUFQRy3iorhvbC9WZuay\nYM0ux/aTse8wLyzbzrVDEhnSqYVj+zEmkCYN7EDnVsEbV1BYXErK2l1c0rut3Z2vDiwIzsKU5CQG\nJDbj0YUbOexAx7Gq8vuUdGKjwrl/nHUQm/qjrFWwYXc+7wehVfDx5n3kHi20sQN1ZEFwFspGHB84\ncoKnl2wN+Osv/HoPyzN8HcStG9tNt039MnFgB7q0juOpJVsdn7DxjVU5tG7ciPO7B2924obEguAs\nDUhqzvVDk/jX55ls3nM4YK979EQxf3h3A33aN+XG4Z0C9rrGBEuEf1zBRodbBQePFrJ0014mDexA\nRLh9pNWFvWsBcO9lvWgSHcG0BYEbcfzMRxnszitg5qS+1kFs6q0JA8paBVscaxW8vW4XRSXK1TbT\naJ1ZEARAy7go7rm0J19uzwDZvkUAAAxGSURBVCVl7dl3HH+z/wjPL9vG5MGJDOnUMgAVGuOOiPAw\nfnVRNzbtOcz7G6q7qWHdzE/Lpnf7pvTp0NSR1/cCC4IAuWFYR85NaMZjCzdy5ERxnV9HVZmekk50\nZDgPWAexaQCu7N+Brg71FWTsO8za7Dwm20jis2JBECDh/hHHe/NPMHtp3TuOF63fw7KtB/j1JT2I\nb2IdxKb+87UKurNpz2EWpwe2VTB/VQ7hYcLEgRYEZ8OCIIAGdWzBlOQk5ny2na17a99xfKywmJnv\nbKBXuyb8aIR1EJuG48oBHegaH8fTSwPXKigpVd5clcOYHvF20HSWLAgC7L6xPYmNCmfagtqPOH72\nowx25RUwc1I/u/rBNCjhYcJd/lbBogC1Cj7/5gB78guskzgA7NMmwFo1bsS9l/VkxbZveWfd7hp/\n3/YDR/nnp9u5elACQztbB7FpeK7o34Fz4uN4OkB9BfPTsmkaHcFFvdsEoDpvsyBwwA+Gd6Jvh6Y8\n+u5Gjtag47isg7hRRBgPjLcOYtMwhYcJv7qoO5v3Hua99WfXKjhcUMSi9D1cOaAD0ZHhAarQuywI\nHBDuH3G8J7+A2R+e2nE85R8rmPKPFacse3/DXj7Zsp+7L+lBmybRwSzVmKA62SpYenbjCt5bv4eC\nolKbaTRALAgcMqRTC64ZksgLy7aTse9IldsdLyxhxtsb6Nm2CTePtA5i07CVtQq27D3CwvU1P3Va\n0fy0bLq2jmOQ3akvICwIHPTAuF7ERIUzPaXqjuO/fZxBzqHjzJjY1zqIjSdc0b8D3do0rnNfQVbu\nMb7cnsvVgxMQsVH3gWCfPA5q3bgR91zak88yDlR6TjTzwFH+/sk2Jg3swPCudqNt4w1lrYKt++rW\nKnhjVQ4icJVdLRQwFgQOu3F4R3q3b8rMdzac0nGsqjzydjpREWH8bnxvFys0JvguP7c93f2tgpJa\ntApUlTdWZzOyaysSmsc4WKG3WBA4LCI8jJkT+7I7r4BnPso4uXzJxn18tHk/d1/cnTZNrYPYeMsp\nrYKva94qSNtxkB3fHmOytQYCyoIgCJI7t+TqwQk8v2wbxwtLKC31tQZ6tG3Mzed1drs8Y1xxslWw\ntOatgvmrsomNCmdsv3YOV+ctFgRB8ttxvYmOCGdH7lF25R0n++BxHpnQj0jrIDYeFRYm3HVxdzL2\nHeHdGrQKCopKeGftbsb2a0dco4ggVOgd9ikUJPFNGhFZXEje8WJyDhUAcM9/v3S5KmPcNb5fe3q0\nbczTS7ZU2yp4f8NeDp8o5ho7LRRwFgRBlFsSRubjV5z8yilw/qbexoSysDDhrot68M3+o7yz7sz3\n8piflk1C8xhG2BV2AWdBYIxx1bh+7ejZtgmzz9BXsC+/gGVb93PVoATC7I59AWdBYIxxVVlfwZla\nBW+tyaFU4Wq7AY0jrMcliBKihc73v3PKc2MMjO3bjl7tmvD00q1c0b8D4WFyck6uubePYH5aDoM6\nNqdrfGOXK22YrEUQRMunj2d4l5YM79KSzFmXs3z6eLdLMiYkhPnvV7Bt/1HernDf7/Rd+Wzee9jG\nDjjIgsAYExIu87cKKvYVzEvLJioijCv7d3CxuobN0SAQkbEisllEMkTkgUrW/1pENojIOhFZKiI2\n/aYxHnWyVXDgKClrcwAoVSVl7S4u6d2WZrGRLlfYcDkWBCISDjwLjAP6ADeISJ8Km60GklW1PzAP\n+F+n6jHGhL6yVsFflmagquQdKyL3aCGTh1gnsZOcbBEMAzJUdZuqFgJzgYnlN1DVj1T1mP/pF4Cd\nBDTGw8LChLsv9rUKDhwpZP+RE7RuHMXo7vFul9agORkECUBWuefZ/mVV+QnwXmUrROR2EUkVkdT9\n+/cHsERjTKi5tE87YkuL2HbgKAePFXHgSCFjZi5yu6wGLSQuHxWRHwLJwPcrW6+qzwHPASQnJ9fr\n4biv/myk2yUYE9LCwoRjYZFkPn7FyWXlL7s2gedkEOQASeWeJ/qXnUJELgYeBL6vqiccrMcYY0wl\nnDw19BXQXUS6iEgUcD2QUn4DERkE/AOYoKr7HKzFGGNMFRxrEahqsYjcASwGwoE5qpouIjOAVFVN\nAf4INAZe9997dKeqTnCqJmNM/WCj8INLqrqpeqhKTk7W1NRUt8swxjisbIoJ61cLDBFJU9XkytbZ\nyGJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPG4kBhZbIwxFdnVQsFjLQJjjPE4CwJjjPE4CwJj\njPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4\nCwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJj\njPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4R4NARMaKyGYRyRCR\nBypZ30hEXvWv/1JEOjtZjzHGmNM5FgQiEg48C4wD+gA3iEifCpv9BDioqt2AJ4HHnarHGGNM5Zxs\nEQwDMlR1m6oWAnOBiRW2mQj82/94HnCRiIiDNRljjKkgwsHXTgCyyj3PBoZXtY2qFotIHtAKOFB+\nIxG5Hbjd//SIiGyuY02tK762x9n7cSp7P75j78WpGsL70amqFU4GQcCo6nPAc2f7OiKSqqrJASip\nQbD341T2fnzH3otTNfT3w8lTQzlAUrnnif5llW4jIhFAM+BbB2syxhhTgZNB8BXQXUS6iEgUcD2Q\nUmGbFOBm/+NrgA9VVR2syRhjTAWOnRryn/O/A1gMhANzVDVdRGYAqaqaArwA/FdEMoBcfGHhpLM+\nvdTA2PtxKns/vmPvxaka9PshdgBujDHeZiOLjTHG4ywIjDHG4zwTBNVNd+EVIpIkIh+JyAYRSReR\nu9yuKRSISLiIrBaRd9yuxW0i0lxE5onIJhHZKCIj3a7JLSLyP/7/k/Ui8oqIRLtdkxM8EQQ1nO7C\nK4qB36hqH2AEMNXD70V5dwEb3S4iRDwNLFLVXsAAPPq+iEgC8CsgWVX74bvoxekLWlzhiSCgZtNd\neIKq7lbVVf7Hh/H9kye4W5W7RCQRuBx43u1a3CYizYDz8V3Rh6oWquohd6tyVQQQ4x/nFAvscrke\nR3glCCqb7sLTH34A/tleBwFfuluJ654C7gNK3S4kBHQB9gP/8p8qe15E4twuyg2qmgP8CdgJ7Aby\nVPV9d6tyhleCwFQgIo2B+cDdqprvdj1uEZErgH2qmuZ2LSEiAhgM/E1VBwFHAU/2qYlIC3xnDroA\nHYA4Efmhu1U5wytBUJPpLjxDRCLxhcDLqvqG2/W4bBQwQUQy8Z0yvFBEXnK3JFdlA9mqWtZKnIcv\nGLzoYmC7qu5X1SLgDeA8l2tyhFeCoCbTXXiCf5rvF4CNqvpnt+txm6r+VlUTVbUzvr+LD1W1QR71\n1YSq7gGyRKSnf9FFwAYXS3LTTmCEiMT6/28uooF2nNeL2UfPVlXTXbhclltGAT8CvhaRNf5lv1PV\nhS7WZELLncDL/oOmbcAtLtfjClX9UkTmAavwXW23mgY61YRNMWGMMR7nlVNDxhhjqmBBYIwxHmdB\nYIwxHmdBYIwxHmdBYIwxHueJy0eNqQ0RKQG+LrdokqpmulSOMY6zy0eNqUBEjqhq4zOsj1DV4mDW\nZIyT7NSQMTUgIj8WkRQR+RBYKiKNRWSpiKwSka9FZKJ/u87+efxfFJEtIvKyiFwsIstFZKuIDPNv\nFycic0RkpX9yN0/OhmtCg7UIjKmgwqmh7ap6lYj8GPgD0F9Vc8umJVbVfBFpDXwBdAc6ARn4ZnVN\nxze9yVrgJ8AE4BZVnSQijwEbVPUlEWkOrAQGqerR4P2kxvhYH4ExpzuuqgMrWf6Bqub6HwvwmIic\nj2/66gSgrX/ddlX9GkBE0oGlqqoi8jXQ2b/Npfgmu7vH/zwa6EgDncvGhDYLAmNqrvzR+o1APDBE\nVYv8s5eW3cbwRLntSss9L+W7/zkBJqvqZufKNaZmrI/AmLpphu8+BkUicgG+U0K1sRi40z+rJSIy\nKNAFGlNTFgTG1M3LQLL/dM9NwKZafv9MIBJY5z99NDPA9RlTY9ZZbIwxHmctAmOM8TgLAmOM8TgL\nAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8bj/D/MaL7bxKI2vAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"sSxFv75xFPuT","colab_type":"text"},"source":["Entropy plot"]},{"cell_type":"code","metadata":{"id":"X_ZcgeZvao6N","colab_type":"code","outputId":"8e792452-abad-412a-c51c-f1da60840cfa","executionInfo":{"status":"ok","timestamp":1578759245494,"user_tz":-60,"elapsed":739,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["plt.plot(range(10), np.mean(np.asarray(entropies),0))\n","plt.title('Entropies')"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Entropies')"]},"metadata":{"tags":[]},"execution_count":24},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"w0zKXZlZFRk4","colab_type":"text"},"source":["Variance plot"]},{"cell_type":"code","metadata":{"id":"XHJIB-mEQ00Q","colab_type":"code","outputId":"2886547e-8036-490a-aa6e-977d70243d00","executionInfo":{"status":"ok","timestamp":1578740466199,"user_tz":-60,"elapsed":1443,"user":{"displayName":"Pred Net","photoUrl":"","userId":"14456830021043738681"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["plt.plot(range(10), np.mean(np.asarray(variances),0))\n","plt.title('Var')"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Var')"]},"metadata":{"tags":[]},"execution_count":52},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+Nz/B0+8ci5XyrdUAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}